{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nina Dobša, zadnje uređivano 7.7.2025.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from gensim.models import Word2Vec\n",
    "from transformers import BertTokenizer, BertForMaskedLM\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold, cross_val_predict\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ISEAR dataset import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7505, 2)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = \"data/isear_3.txt\"  \n",
    "ISEAR_data = pd.read_csv(file_path, delimiter=\"|\", header=0, on_bad_lines=\"skip\", engine=\"python\")\n",
    "\n",
    "# Select only Emotion and Text columns from original dataset\n",
    "ISEAR_data = ISEAR_data[['SIT', 'Field1']]  # Emotion and last column (Text)\n",
    "ISEAR_data.columns = ['text', 'emotion'] # Naming the columns\n",
    "\n",
    "ISEAR_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'anger': 0, 'disgust': 1, 'fear': 2, 'guilt': 3, 'joy': 4, 'sadness': 5, 'shame': 6}\n"
     ]
    }
   ],
   "source": [
    "# Encoding emotions (from words to numbers)\n",
    "label_encoder = LabelEncoder()\n",
    "ISEAR_data['emotion_label'] = label_encoder.fit_transform(ISEAR_data['emotion'])\n",
    "print(dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "      <th>emotion_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>During the period of falling in love, each tim...</td>\n",
       "      <td>joy</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When I was involved in a traffic accident.</td>\n",
       "      <td>fear</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>When I was driving home after  several days of...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>When I lost the person who meant the most to me.</td>\n",
       "      <td>sadness</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The time I knocked a deer down - the sight of ...</td>\n",
       "      <td>disgust</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  emotion  emotion_label\n",
       "0  During the period of falling in love, each tim...      joy              4\n",
       "1         When I was involved in a traffic accident.     fear              2\n",
       "2  When I was driving home after  several days of...    anger              0\n",
       "3  When I lost the person who meant the most to me.   sadness              5\n",
       "4  The time I knocked a deer down - the sight of ...  disgust              1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ISEAR_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import of fine tuned word2vec model\n",
    "model_path_SG = \"fine_tuned_word2vec_sg/fine_tuned_word2vec_sg.model\"\n",
    "model_path_CBOW = \"fine_tuned_word2vec_cbow/fine_tuned_word2vec_cbow.model\"\n",
    "word2vec_model_SG = Word2Vec.load(model_path_SG)\n",
    "word2vec_model_CBOW = Word2Vec.load(model_path_CBOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that returns the word2vec embedding for a given sentence\n",
    "def get_word2vec_embedding(sentence, word2vec_model):\n",
    "    \n",
    "    words = sentence.split()     # Tokenization\n",
    "    word_embeddings = [word2vec_model.wv[word] for word in words if word in word2vec_model.wv] # Get embeddings for words that exist in the Word2Vec vocabulary\n",
    "    \n",
    "    if not word_embeddings:  # If no words are in the vocabulary, return a zero vector\n",
    "        return np.zeros(word2vec_model.vector_size)\n",
    "    \n",
    "    sentence_embedding = np.mean(word_embeddings, axis=0) # Calculate the mean of all word embeddings to get the emdedding for sentence\n",
    "    return sentence_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding new \"word2vec_embedding_SG\" and \"word2vec_embedding_CBOW\" column to ISEAR dataset\n",
    "# Applying get_word2vec_embedding to all sentences\n",
    "\n",
    "ISEAR_data['word2vec_embedding_SG'] = ISEAR_data['text'].apply(\n",
    "    lambda sentence: get_word2vec_embedding(sentence, word2vec_model_SG)\n",
    ")\n",
    "\n",
    "ISEAR_data['word2vec_embedding_CBOW'] = ISEAR_data['text'].apply(\n",
    "    lambda sentence: get_word2vec_embedding(sentence, word2vec_model_CBOW)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "      <th>emotion_label</th>\n",
       "      <th>word2vec_embedding_SG</th>\n",
       "      <th>word2vec_embedding_CBOW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>During the period of falling in love, each tim...</td>\n",
       "      <td>joy</td>\n",
       "      <td>4</td>\n",
       "      <td>[-0.049276937, 0.13258511, -0.08547431, 0.0617...</td>\n",
       "      <td>[-0.12927012, -0.39089495, 0.5890891, -0.44857...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When I was involved in a traffic accident.</td>\n",
       "      <td>fear</td>\n",
       "      <td>2</td>\n",
       "      <td>[-0.0098165795, 0.15902604, -0.068388596, -0.0...</td>\n",
       "      <td>[0.19186452, -0.037524782, 0.6663514, -0.10714...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>When I was driving home after  several days of...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0412013, 0.24119537, -0.07577773, 0.0033492...</td>\n",
       "      <td>[0.035169117, -0.06991781, 0.6389158, -0.00986...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>When I lost the person who meant the most to me.</td>\n",
       "      <td>sadness</td>\n",
       "      <td>5</td>\n",
       "      <td>[-0.09790471, 0.12274621, -0.08426029, 0.05351...</td>\n",
       "      <td>[-0.079096586, -0.24543297, 0.48515487, -0.104...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The time I knocked a deer down - the sight of ...</td>\n",
       "      <td>disgust</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0071739783, 0.1709428, -0.07293872, 0.07204...</td>\n",
       "      <td>[0.112791084, 0.0432981, 0.31216973, -0.117237...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  emotion  emotion_label  \\\n",
       "0  During the period of falling in love, each tim...      joy              4   \n",
       "1         When I was involved in a traffic accident.     fear              2   \n",
       "2  When I was driving home after  several days of...    anger              0   \n",
       "3  When I lost the person who meant the most to me.   sadness              5   \n",
       "4  The time I knocked a deer down - the sight of ...  disgust              1   \n",
       "\n",
       "                               word2vec_embedding_SG  \\\n",
       "0  [-0.049276937, 0.13258511, -0.08547431, 0.0617...   \n",
       "1  [-0.0098165795, 0.15902604, -0.068388596, -0.0...   \n",
       "2  [0.0412013, 0.24119537, -0.07577773, 0.0033492...   \n",
       "3  [-0.09790471, 0.12274621, -0.08426029, 0.05351...   \n",
       "4  [0.0071739783, 0.1709428, -0.07293872, 0.07204...   \n",
       "\n",
       "                             word2vec_embedding_CBOW  \n",
       "0  [-0.12927012, -0.39089495, 0.5890891, -0.44857...  \n",
       "1  [0.19186452, -0.037524782, 0.6663514, -0.10714...  \n",
       "2  [0.035169117, -0.06991781, 0.6389158, -0.00986...  \n",
       "3  [-0.079096586, -0.24543297, 0.48515487, -0.104...  \n",
       "4  [0.112791084, 0.0432981, 0.31216973, -0.117237...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ISEAR_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML predictions for Word2Vec embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the Random Forest classifier\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining 5-fold cross-validation\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skip Gram method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data\n",
    "X_SG = np.array(ISEAR_data['word2vec_embedding_SG'].tolist()) \n",
    "y = ISEAR_data['emotion_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing 5-fold cross validation\n",
    "scoring_metrics = ['accuracy', 'precision_macro', 'recall_macro', 'f1_macro']\n",
    "scores_SG = cross_validate(clf, X_SG, y, cv=kf, scoring=scoring_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.3928 +/- 0.005892963194535902\n",
      "precision_macro: 0.3890 +/- 0.006447946386094139\n",
      "recall_macro: 0.3930 +/- 0.005951894938131344\n",
      "f1_macro: 0.3889 +/- 0.005286286793141579\n"
     ]
    }
   ],
   "source": [
    "# Calculation of average scores\n",
    "for metric in scoring_metrics:\n",
    "    avg_score_SG = np.mean(scores_SG[f'test_{metric}'])\n",
    "    std_dev_SG = np.std(scores_SG[f'test_{metric}'])\n",
    "\n",
    "    print(f\"{metric}: {avg_score_SG:.4f} +/- {std_dev_SG:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[332 152 114 170  97  91 114]\n",
      " [170 395 157  88  73  67 108]\n",
      " [ 83  96 596  90  75  70  69]\n",
      " [197  89 112 345  95  99 133]\n",
      " [ 84  61  64  66 607 117  66]\n",
      " [112  70  94 129 126 440 109]\n",
      " [179 133 150 202  99  87 233]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion matrix calculation\n",
    "y_pred_SG = cross_val_predict(clf, X_SG, y, cv=kf)\n",
    "cm = confusion_matrix(y, y_pred_SG)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CBOW method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data\n",
    "X_CBOW = np.array(ISEAR_data['word2vec_embedding_CBOW'].tolist()) \n",
    "y = ISEAR_data['emotion_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing 5-fold cross validation\n",
    "scoring_metrics = ['accuracy', 'precision_macro', 'recall_macro', 'f1_macro']\n",
    "scores_CBOW = cross_validate(clf, X_CBOW, y, cv=kf, scoring=scoring_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.3560 +/- 0.012672946315176197\n",
      "precision_macro: 0.3509 +/- 0.01259861919672469\n",
      "recall_macro: 0.3562 +/- 0.012743103499281296\n",
      "f1_macro: 0.3510 +/- 0.012279997900399263\n"
     ]
    }
   ],
   "source": [
    "# Calculation of average scores\n",
    "for metric in scoring_metrics:\n",
    "    avg_score_CBOW = np.mean(scores_CBOW[f'test_{metric}'])\n",
    "    std_dev_CBOW = np.std(scores_CBOW[f'test_{metric}'])\n",
    "\n",
    "    print(f\"{metric}: {avg_score_CBOW:.4f} +/- {std_dev_CBOW:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[315 146 131 176  97  90 115]\n",
      " [176 351 156 102  95  69 109]\n",
      " [ 99  94 565  87  87  76  71]\n",
      " [188 115 107 302 101 119 138]\n",
      " [ 98  88  76  65 560 116  62]\n",
      " [130  85  98 126 166 369 106]\n",
      " [172 149 149 188 112 103 210]]\n"
     ]
    }
   ],
   "source": [
    "# Calculating confusion matrix\n",
    "y_pred_CBOW = cross_val_predict(clf, X_CBOW, y, cv=kf)\n",
    "cm = confusion_matrix(y, y_pred_CBOW)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import of fine tuned bert model\n",
    "model_path = \"fine_tuned_bert\"\n",
    "bert_tokenizer = BertTokenizer.from_pretrained(model_path)\n",
    "bert_model = BertForMaskedLM.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that returns bert embedding for an input sentence\n",
    "def get_bert_embedding_sentence(sentence, model, tokenizer):\n",
    "\n",
    "    # Tokenize the input sentence\n",
    "    inputs = tokenizer(\n",
    "        sentence,\n",
    "        return_tensors='pt',  \n",
    "        truncation=True,     \n",
    "        padding=True          \n",
    "    )\n",
    "\n",
    "    # Forward pass through the model to get hidden states\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs, output_hidden_states=True)\n",
    "\n",
    "    # Extract the last hidden state \n",
    "    hidden_states = outputs.hidden_states[-1]  \n",
    "\n",
    "    # Compute the mean pooling of token embeddings\n",
    "    sentence_embedding = hidden_states.mean(dim=1).squeeze().numpy()\n",
    "\n",
    "    return sentence_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying get_bert_embeddings_sentence to all sentences in train, validation and test data\n",
    "bert_model.eval()\n",
    "ISEAR_data[\"bert_embedding\"] = ISEAR_data[\"text\"].apply(\n",
    "     lambda sentence: get_bert_embedding_sentence(sentence, bert_model, bert_tokenizer)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML prediction for BERT embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data\n",
    "X_bert = np.array(ISEAR_data['bert_embedding'].tolist()) \n",
    "y = ISEAR_data['emotion_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing 5-fold cross validation\n",
    "scoring_metrics = ['accuracy', 'precision_macro', 'recall_macro', 'f1_macro']\n",
    "scores_bert = cross_validate(clf, X_bert, y, cv=kf, scoring=scoring_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.5183 +/- 0.0122\n",
      "precision_macro: 0.5135 +/- 0.0121\n",
      "recall_macro: 0.5187 +/- 0.0122\n",
      "f1_macro: 0.5136 +/- 0.0122\n"
     ]
    }
   ],
   "source": [
    "# Calculating the average scores\n",
    "for metric in scoring_metrics:\n",
    "    avg_score_BERT = np.mean(scores_bert[f'test_{metric}'])\n",
    "    std_dev_BERT = np.std(scores_bert[f'test_{metric}'])\n",
    "    \n",
    "    print(f\"{metric}: {avg_score_BERT:.4f} +/- {std_dev_BERT:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[424 156  72 184  60  52 122]\n",
      " [197 555  68  65  45  42  86]\n",
      " [ 55  71 690  53  76  83  51]\n",
      " [194  65  81 417  54  88 171]\n",
      " [ 21  17  29  36 848  79  35]\n",
      " [ 82  60  54  69 160 588  67]\n",
      " [182 121  98 186  86  42 368]]\n"
     ]
    }
   ],
   "source": [
    "# Calculating confusion matrix\n",
    "y_pred_bert = cross_val_predict(clf, X_bert, y, cv=kf)\n",
    "cm = confusion_matrix(y, y_pred_bert)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
