{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nina Dobša, zadnje uređivano 7.7.2025.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nina\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from gensim.models import Word2Vec\n",
    "from transformers import BertTokenizer, BertForMaskedLM\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold, cross_val_predict\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GoEmotions dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = {'train': 'simplified/train-00000-of-00001.parquet', \n",
    "          'validation': 'simplified/validation-00000-of-00001.parquet', \n",
    "          'test': 'simplified/test-00000-of-00001.parquet'}\n",
    "\n",
    "goemotions_train = pd.read_parquet(\"hf://datasets/google-research-datasets/go_emotions/\" + splits[\"train\"])\n",
    "goemotions_validation = pd.read_parquet(\"hf://datasets/google-research-datasets/go_emotions/\" + splits[\"validation\"])\n",
    "goemotions_test = pd.read_parquet(\"hf://datasets/google-research-datasets/go_emotions/\" + splits[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "goemotions_data = pd.concat([goemotions_train, goemotions_validation, goemotions_test], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54263, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goemotions_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning and labeling emotions with 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping numbers from labels with emotions\n",
    "emotion_dictionary = { 0 : 'admiration', 1 : 'amusement', 2 : 'anger', 3 : 'annoyance', 4 : 'approval', 5 : 'caring', 6 : 'confusion', 7 : 'curiosity', 8 : 'desire',\n",
    "                      9 : 'disappointment', 10 : 'disapproval', 11 : 'disgust', 12 : 'embarrassment', 13 : 'excitement', 14 : 'fear', 15 : 'gratitude', 16 : 'grief',\n",
    "                      17 : 'joy', 18 : 'love', 19 : 'nervousness', 20 : 'optimism', 21 : 'pride', 22 : 'realization', 23 : 'relief', 24 : 'remorse', 25 : 'sadness',\n",
    "                      26 : 'surprise', 27 : 'neutral' }\n",
    "\n",
    "\n",
    "target_emotions = {'anger': 2, 'sadness': 25, 'joy': 17, 'disgust' : 11, 'surprise' : 26}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating new columns for each emotion (anger, joy, sadness, disgust, surprise)\n",
    "# in train, validation and test goemotion datasets\n",
    "for emotion, label in target_emotions.items():\n",
    "    goemotions_data[emotion] = goemotions_data['labels'].apply(lambda x: 1 if label in x else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping id and labels columns, we don't need them\n",
    "goemotions_data = goemotions_data.drop(columns = [\"id\", \"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>anger</th>\n",
       "      <th>sadness</th>\n",
       "      <th>joy</th>\n",
       "      <th>disgust</th>\n",
       "      <th>surprise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My favourite food is anything I didn't have to...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Now if he does off himself, everyone will thin...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WHY THE FUCK IS BAYLESS ISOING</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>To make her feel threatened</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dirty Southern Wankers</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  anger  sadness  joy  \\\n",
       "0  My favourite food is anything I didn't have to...      0        0    0   \n",
       "1  Now if he does off himself, everyone will thin...      0        0    0   \n",
       "2                     WHY THE FUCK IS BAYLESS ISOING      1        0    0   \n",
       "3                        To make her feel threatened      0        0    0   \n",
       "4                             Dirty Southern Wankers      0        0    0   \n",
       "\n",
       "   disgust  surprise  \n",
       "0        0         0  \n",
       "1        0         0  \n",
       "2        0         0  \n",
       "3        0         0  \n",
       "4        0         0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goemotions_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import of fine tuned word2vec model\n",
    "model_path_SG = \"fine_tuned_word2vec_sg/fine_tuned_word2vec_sg.model\"\n",
    "model_path_CBOW = \"fine_tuned_word2vec_cbow/fine_tuned_word2vec_cbow.model\"\n",
    "word2vec_model_SG = Word2Vec.load(model_path_SG)\n",
    "word2vec_model_CBOW = Word2Vec.load(model_path_CBOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that returns the word2vec embedding for a given sentence\n",
    "def get_word2vec_embedding(sentence, word2vec_model):\n",
    "    words = sentence.split()     # Tokenization\n",
    "    word_embeddings = [word2vec_model.wv[word] for word in words if word in word2vec_model.wv] # Get embeddings for words that exist in the Word2Vec vocabulary\n",
    "    \n",
    "    if not word_embeddings:  # If no words are in the vocabulary, return a zero vector\n",
    "        return np.zeros(word2vec_model.vector_size)\n",
    "    \n",
    "    sentence_embedding = np.mean(word_embeddings, axis=0) # compute the mean of all word embeddings to get the emdedding for sentence\n",
    "    return sentence_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding new \"word2vec_embedding\" column to train, test and validation goemotion datasets \n",
    "# Applying get_word2vec_embedding to all sentences\n",
    "goemotions_data['word2vec_embedding_SG'] = goemotions_data['text'].apply(\n",
    "    lambda sentence: get_word2vec_embedding(sentence, word2vec_model_SG)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding new \"word2vec_embedding\" column to train, test and validation goemotion datasets \n",
    "# Applying get_word2vec_embedding to all sentences\n",
    "goemotions_data['word2vec_embedding_CBOW'] = goemotions_data['text'].apply(\n",
    "    lambda sentence: get_word2vec_embedding(sentence, word2vec_model_CBOW)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>anger</th>\n",
       "      <th>sadness</th>\n",
       "      <th>joy</th>\n",
       "      <th>disgust</th>\n",
       "      <th>surprise</th>\n",
       "      <th>word2vec_embedding_SG</th>\n",
       "      <th>word2vec_embedding_CBOW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54258</th>\n",
       "      <td>Thanks. I was diagnosed with BP 1 after the ho...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.011911079, 0.1247393, -0.03292984, -0.0216...</td>\n",
       "      <td>[-0.35409313, 0.18309589, 0.7523857, -0.554011...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54259</th>\n",
       "      <td>Well that makes sense.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.053056713, 0.366973, -0.03590046, -0.05008...</td>\n",
       "      <td>[-0.49808195, -0.40611854, 0.55714554, -0.2184...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54260</th>\n",
       "      <td>Daddy issues [NAME]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.09085079, 0.40177393, -0.027788045, 0.1444...</td>\n",
       "      <td>[0.10302511, 0.25298855, 0.85893273, 0.8379355...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54261</th>\n",
       "      <td>So glad I discovered that subreddit a couple m...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.095128104, 0.26241234, 0.091321245, 0.07458...</td>\n",
       "      <td>[0.3417902, -0.33821112, 1.1506916, -0.2599661...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54262</th>\n",
       "      <td>Had to watch \"Elmo in Grouchland\" one time too...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.020561595, 0.23708051, -0.13485207, -0.0036...</td>\n",
       "      <td>[0.07777702, -0.30598238, 0.44885072, -0.04225...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  anger  sadness  joy  \\\n",
       "54258  Thanks. I was diagnosed with BP 1 after the ho...      0        0    0   \n",
       "54259                             Well that makes sense.      0        0    0   \n",
       "54260                                Daddy issues [NAME]      0        0    0   \n",
       "54261  So glad I discovered that subreddit a couple m...      0        0    0   \n",
       "54262  Had to watch \"Elmo in Grouchland\" one time too...      0        0    0   \n",
       "\n",
       "       disgust  surprise                              word2vec_embedding_SG  \\\n",
       "54258        0         0  [-0.011911079, 0.1247393, -0.03292984, -0.0216...   \n",
       "54259        0         0  [-0.053056713, 0.366973, -0.03590046, -0.05008...   \n",
       "54260        0         0  [-0.09085079, 0.40177393, -0.027788045, 0.1444...   \n",
       "54261        0         0  [0.095128104, 0.26241234, 0.091321245, 0.07458...   \n",
       "54262        0         0  [0.020561595, 0.23708051, -0.13485207, -0.0036...   \n",
       "\n",
       "                                 word2vec_embedding_CBOW  \n",
       "54258  [-0.35409313, 0.18309589, 0.7523857, -0.554011...  \n",
       "54259  [-0.49808195, -0.40611854, 0.55714554, -0.2184...  \n",
       "54260  [0.10302511, 0.25298855, 0.85893273, 0.8379355...  \n",
       "54261  [0.3417902, -0.33821112, 1.1506916, -0.2599661...  \n",
       "54262  [0.07777702, -0.30598238, 0.44885072, -0.04225...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goemotions_data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML algorithms for word2vec emdeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the Random Forest classifier\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining 5-fold cross-validation\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skip gram method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data\n",
    "X_SG = np.array(goemotions_data['word2vec_embedding_SG'].tolist())   # Word embeddings as features\n",
    "\n",
    "y_anger = goemotions_data['anger']  \n",
    "y_joy = goemotions_data['joy']\n",
    "y_sadness = goemotions_data['sadness']\n",
    "y_disgust = goemotions_data['disgust']\n",
    "y_surprise = goemotions_data['surprise']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nina\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Performing 5-fold cross validation\n",
    "scoring_metrics = ['accuracy', 'precision_macro', 'recall_macro', 'f1_macro']\n",
    "scores_anger_sg = cross_validate(clf, X_SG, y_anger, cv=kf, scoring=scoring_metrics)\n",
    "scores_joy_sg = cross_validate(clf, X_SG, y_joy, cv=kf, scoring=scoring_metrics)\n",
    "scores_sadness_sg = cross_validate(clf, X_SG, y_sadness, cv=kf, scoring=scoring_metrics)\n",
    "scores_disgust_sg = cross_validate(clf, X_SG, y_disgust, cv=kf, scoring=scoring_metrics)\n",
    "scores_surprise_sg = cross_validate(clf, X_SG, y_surprise, cv=kf, scoring=scoring_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy anger: 0.9636 +/- 0.0002\n",
      "accuracy joy: 0.9671 +/- 0.0005\n",
      "accuracy sadness: 0.9700 +/- 0.0001\n",
      "accuracy disgust: 0.9812 +/- 0.0002\n",
      "accuracy surprise: 0.9750 +/- 0.0002\n",
      "\n",
      "\n",
      "precision_macro anger: 0.7048 +/- 0.0202\n",
      "precision_macro joy: 0.7270 +/- 0.0941\n",
      "precision_macro sadness: 0.7311 +/- 0.0516\n",
      "precision_macro disgust: 0.6783 +/- 0.1714\n",
      "precision_macro surprise: 0.5220 +/- 0.0430\n",
      "\n",
      "\n",
      "recall_macro anger: 0.5131 +/- 0.0011\n",
      "recall_macro joy: 0.5119 +/- 0.0050\n",
      "recall_macro sadness: 0.5066 +/- 0.0020\n",
      "recall_macro disgust: 0.5024 +/- 0.0015\n",
      "recall_macro surprise: 0.5005 +/- 0.0009\n",
      "\n",
      "\n",
      "f1_macro anger: 0.5166 +/- 0.0021\n",
      "f1_macro joy: 0.5151 +/- 0.0095\n",
      "f1_macro sadness: 0.5055 +/- 0.0040\n",
      "f1_macro disgust: 0.5001 +/- 0.0030\n",
      "f1_macro surprise: 0.4951 +/- 0.0018\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculating and printing the avg score +/- std dev\n",
    "for metric in scoring_metrics:\n",
    "    avg_score_anger_sg = np.mean(scores_anger_sg[f'test_{metric}'])\n",
    "    std_dev_anger_sg = np.std(scores_anger_sg[f'test_{metric}'])\n",
    "\n",
    "    avg_score_joy_sg = np.mean(scores_joy_sg[f'test_{metric}'])\n",
    "    std_dev_joy_sg = np.std(scores_joy_sg[f'test_{metric}'])\n",
    "\n",
    "    avg_score_sadness_sg = np.mean(scores_sadness_sg[f'test_{metric}'])\n",
    "    std_dev_sadness_sg = np.std(scores_sadness_sg[f'test_{metric}'])\n",
    "\n",
    "    avg_score_disgust_sg = np.mean(scores_disgust_sg[f'test_{metric}'])\n",
    "    std_dev_disgust_sg = np.std(scores_disgust_sg[f'test_{metric}'])\n",
    "\n",
    "    avg_score_surprise_sg = np.mean(scores_surprise_sg[f'test_{metric}'])\n",
    "    std_dev_surprise_sg = np.std(scores_surprise_sg[f'test_{metric}'])\n",
    "\n",
    "\n",
    "    print(f\"{metric} anger: {avg_score_anger_sg:.4f} +/- {std_dev_anger_sg:.4f}\")\n",
    "    print(f\"{metric} joy: {avg_score_joy_sg:.4f} +/- {std_dev_joy_sg:.4f}\")\n",
    "    print(f\"{metric} sadness: {avg_score_sadness_sg:.4f} +/- {std_dev_sadness_sg:.4f}\")\n",
    "    print(f\"{metric} disgust: {avg_score_disgust_sg:.4f} +/- {std_dev_disgust_sg:.4f}\")\n",
    "    print(f\"{metric} surprise: {avg_score_surprise_sg:.4f} +/- {std_dev_surprise_sg:.4f}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CBOW method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data\n",
    "X_CBOW = np.array(goemotions_data['word2vec_embedding_CBOW'].tolist())  # Word embeddings as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nina\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Nina\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Performing 5-fold cross validation\n",
    "scoring_metrics = ['accuracy', 'precision_macro', 'recall_macro', 'f1_macro']\n",
    "scores_anger_cbow = cross_validate(clf, X_CBOW, y_anger, cv=kf, scoring=scoring_metrics)\n",
    "scores_joy_cbow = cross_validate(clf, X_CBOW, y_joy, cv=kf, scoring=scoring_metrics)\n",
    "scores_sadness_cbow = cross_validate(clf, X_CBOW, y_sadness, cv=kf, scoring=scoring_metrics)\n",
    "scores_disgust_cbow = cross_validate(clf, X_CBOW, y_disgust, cv=kf, scoring=scoring_metrics)\n",
    "scores_surprise_cbow = cross_validate(clf, X_CBOW, y_surprise, cv=kf, scoring=scoring_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy anger: 0.9635 +/- 0.0001\n",
      "accuracy joy: 0.9670 +/- 0.0004\n",
      "accuracy sadness: 0.9699 +/- 0.0001\n",
      "accuracy disgust: 0.9812 +/- 0.0002\n",
      "accuracy surprise: 0.9750 +/- 0.0002\n",
      "\n",
      "\n",
      "precision_macro anger: 0.6880 +/- 0.0184\n",
      "precision_macro joy: 0.7045 +/- 0.0844\n",
      "precision_macro sadness: 0.7031 +/- 0.0467\n",
      "precision_macro disgust: 0.5907 +/- 0.0972\n",
      "precision_macro surprise: 0.5203 +/- 0.0416\n",
      "\n",
      "\n",
      "recall_macro anger: 0.5109 +/- 0.0022\n",
      "recall_macro joy: 0.5091 +/- 0.0043\n",
      "recall_macro sadness: 0.5065 +/- 0.0024\n",
      "recall_macro disgust: 0.5024 +/- 0.0021\n",
      "recall_macro surprise: 0.5005 +/- 0.0009\n",
      "\n",
      "\n",
      "f1_macro anger: 0.5124 +/- 0.0042\n",
      "f1_macro joy: 0.5098 +/- 0.0082\n",
      "f1_macro sadness: 0.5055 +/- 0.0047\n",
      "f1_macro disgust: 0.5001 +/- 0.0043\n",
      "f1_macro surprise: 0.4951 +/- 0.0018\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculating and printing the avg score +/- std dev\n",
    "for metric in scoring_metrics:\n",
    "    avg_score_anger_cbow = np.mean(scores_anger_cbow[f'test_{metric}'])\n",
    "    std_dev_anger_cbow = np.std(scores_anger_cbow[f'test_{metric}'])\n",
    "\n",
    "    avg_score_joy_cbow = np.mean(scores_joy_cbow[f'test_{metric}'])\n",
    "    std_dev_joy_cbow = np.std(scores_joy_cbow[f'test_{metric}'])\n",
    "\n",
    "    avg_score_sadness_cbow = np.mean(scores_sadness_cbow[f'test_{metric}'])\n",
    "    std_dev_sadness_cbow = np.std(scores_sadness_cbow[f'test_{metric}'])\n",
    "\n",
    "    avg_score_disgust_cbow = np.mean(scores_disgust_cbow[f'test_{metric}'])\n",
    "    std_dev_disgust_cbow = np.std(scores_disgust_cbow[f'test_{metric}'])\n",
    "\n",
    "    avg_score_surprise_cbow = np.mean(scores_surprise_cbow[f'test_{metric}'])\n",
    "    std_dev_surprise_cbow = np.std(scores_surprise_cbow[f'test_{metric}'])\n",
    "\n",
    "\n",
    "    print(f\"{metric} anger: {avg_score_anger_cbow:.4f} +/- {std_dev_anger_cbow:.4f}\")\n",
    "    print(f\"{metric} joy: {avg_score_joy_cbow:.4f} +/- {std_dev_joy_cbow:.4f}\")\n",
    "    print(f\"{metric} sadness: {avg_score_sadness_cbow:.4f} +/- {std_dev_sadness_cbow:.4f}\")\n",
    "    print(f\"{metric} disgust: {avg_score_disgust_cbow:.4f} +/- {std_dev_disgust_cbow:.4f}\")\n",
    "    print(f\"{metric} surprise: {avg_score_surprise_cbow:.4f} +/- {std_dev_surprise_cbow:.4f}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertForMaskedLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n"
     ]
    }
   ],
   "source": [
    "# Import of fine tuned bert model\n",
    "model_path = \"fine_tuned_bert\"\n",
    "bert_tokenizer = BertTokenizer.from_pretrained(model_path)\n",
    "bert_model = BertForMaskedLM.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that returns bert embedding for an input sentence\n",
    "def get_bert_embedding_sentence(sentence, model, tokenizer):\n",
    "    # Tokenize the input sentence\n",
    "    inputs = tokenizer(\n",
    "        sentence,\n",
    "        return_tensors='pt',  # PyTorch tensors\n",
    "        truncation=True,      # Truncate if the sentence is too long\n",
    "        padding=True          # Add padding to match the model's input size\n",
    "    )\n",
    "\n",
    "    # Forward pass through the model to get hidden states\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs, output_hidden_states=True)\n",
    "\n",
    "    # Extract the last hidden state (we assume it’s the first hidden state)\n",
    "    hidden_states = outputs.hidden_states[-1]  # Get the last hidden state from all layers\n",
    "\n",
    "    # Compute the mean pooling of token embeddings\n",
    "    sentence_embedding = hidden_states.mean(dim=1).squeeze().numpy()\n",
    "\n",
    "    return sentence_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying get_bert_embeddings_sentence to all sentences in goemotions_data\n",
    "bert_model.eval()\n",
    "goemotions_data[\"bert_embedding\"] = goemotions_data[\"text\"].apply(\n",
    "     lambda sentence: get_bert_embedding_sentence(sentence, bert_model, bert_tokenizer)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML elgorithms for bert embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data\n",
    "X_BERT = np.array(goemotions_data['bert_embedding'].tolist())  # Word embeddings as features\n",
    "\n",
    "y_anger = goemotions_data['anger']  \n",
    "y_joy = goemotions_data['joy']\n",
    "y_sadness = goemotions_data['sadness']\n",
    "y_disgust = goemotions_data['disgust']\n",
    "y_surprise = goemotions_data['surprise']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nina\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Nina\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Nina\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Nina\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Performing 5-fold cross validation\n",
    "scoring_metrics = ['accuracy', 'precision_macro', 'recall_macro', 'f1_macro']\n",
    "\n",
    "scores_anger_bert = cross_validate(clf, X_BERT, y_anger, cv=kf, scoring=scoring_metrics)\n",
    "scores_joy_bert = cross_validate(clf, X_BERT, y_joy, cv=kf, scoring=scoring_metrics)\n",
    "scores_sadness_bert = cross_validate(clf, X_BERT, y_sadness, cv=kf, scoring=scoring_metrics)\n",
    "scores_disgust_bert = cross_validate(clf, X_BERT, y_disgust, cv=kf, scoring=scoring_metrics)\n",
    "scores_surprise_bert = cross_validate(clf, X_BERT, y_surprise, cv=kf, scoring=scoring_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy anger: 0.9642 +/- 0.0003\n",
      "accuracy joy: 0.9671 +/- 0.0002\n",
      "accuracy sadness: 0.9702 +/- 0.0001\n",
      "accuracy disgust: 0.9814 +/- 0.0001\n",
      "accuracy surprise: 0.9755 +/- 0.0000\n",
      "\n",
      "\n",
      "precision_macro anger: 0.8040 +/- 0.1019\n",
      "precision_macro joy: 0.7328 +/- 0.1434\n",
      "precision_macro sadness: 0.8601 +/- 0.1118\n",
      "precision_macro disgust: 0.7207 +/- 0.2040\n",
      "precision_macro surprise: 0.6878 +/- 0.1871\n",
      "\n",
      "\n",
      "recall_macro anger: 0.5078 +/- 0.0039\n",
      "recall_macro joy: 0.5035 +/- 0.0019\n",
      "recall_macro sadness: 0.5030 +/- 0.0010\n",
      "recall_macro disgust: 0.5039 +/- 0.0037\n",
      "recall_macro surprise: 0.5015 +/- 0.0014\n",
      "\n",
      "\n",
      "f1_macro anger: 0.5063 +/- 0.0076\n",
      "f1_macro joy: 0.4988 +/- 0.0038\n",
      "f1_macro sadness: 0.4985 +/- 0.0019\n",
      "f1_macro disgust: 0.5031 +/- 0.0073\n",
      "f1_macro surprise: 0.4968 +/- 0.0028\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculating and printing the avg score +/- std dev\n",
    "for metric in scoring_metrics:\n",
    "    avg_score_anger_bert = np.mean(scores_anger_bert[f'test_{metric}'])\n",
    "    std_dev_anger_bert = np.std(scores_anger_bert[f'test_{metric}'])\n",
    "\n",
    "    avg_score_joy_bert = np.mean(scores_joy_bert[f'test_{metric}'])\n",
    "    std_dev_joy_bert = np.std(scores_joy_bert[f'test_{metric}'])\n",
    "\n",
    "    avg_score_sadness_bert = np.mean(scores_sadness_bert[f'test_{metric}'])\n",
    "    std_dev_sadness_bert = np.std(scores_sadness_bert[f'test_{metric}'])\n",
    "\n",
    "    avg_score_disgust_bert = np.mean(scores_disgust_bert[f'test_{metric}'])\n",
    "    std_dev_disgust_bert = np.std(scores_disgust_bert[f'test_{metric}'])\n",
    "\n",
    "    avg_score_surprise_bert = np.mean(scores_surprise_bert[f'test_{metric}'])\n",
    "    std_dev_surprise_bert = np.std(scores_surprise_bert[f'test_{metric}'])\n",
    "\n",
    "\n",
    "    print(f\"{metric} anger: {avg_score_anger_bert:.4f} +/- {std_dev_anger_bert:.4f}\")\n",
    "    print(f\"{metric} joy: {avg_score_joy_bert:.4f} +/- {std_dev_joy_bert:.4f}\")\n",
    "    print(f\"{metric} sadness: {avg_score_sadness_bert:.4f} +/- {std_dev_sadness_bert:.4f}\")\n",
    "    print(f\"{metric} disgust: {avg_score_disgust_bert:.4f} +/- {std_dev_disgust_bert:.4f}\")\n",
    "    print(f\"{metric} surprise: {avg_score_surprise_bert:.4f} +/- {std_dev_surprise_bert:.4f}\")\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
