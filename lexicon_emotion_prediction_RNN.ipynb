{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "acba64ff",
      "metadata": {
        "id": "acba64ff"
      },
      "source": [
        "**Nina Dobša, 28.7.2025.**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5154911a",
      "metadata": {
        "id": "5154911a"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "id": "z6O9iyAoUnUH",
        "outputId": "7e906314-624c-40e6-e9af-5ee43dd5fa83"
      },
      "id": "z6O9iyAoUnUH",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gensim\n",
            "  Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
            "Collecting numpy<2.0,>=1.18.5 (from gensim)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy<1.14.0,>=1.7.0 (from gensim)\n",
            "  Downloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.3.0.post1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n",
            "Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.7/26.7 MB\u001b[0m \u001b[31m104.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m124.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m67.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy, scipy, gensim\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.16.0\n",
            "    Uninstalling scipy-1.16.0:\n",
            "      Successfully uninstalled scipy-1.16.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "tsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.13.1 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gensim-4.3.3 numpy-1.26.4 scipy-1.13.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "d376d90d1de94ac4903b8b0d604a6805"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "2648e535",
      "metadata": {
        "id": "2648e535"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datasets import load_dataset\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional, Input\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.backend import clear_session\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from gensim.models import Word2Vec\n",
        "from transformers import BertTokenizer, BertForMaskedLM\n",
        "import torch\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57247d4e",
      "metadata": {
        "id": "57247d4e"
      },
      "source": [
        "# Data import - NRC Emotion Lexicon"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Connecting with google drive where fine tuned models are stored\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKXMzjRALI-C",
        "outputId": "cc7624ac-21dd-4c0f-e840-f5cc1f9f5e97"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "id": "HKXMzjRALI-C"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "61e12afd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61e12afd",
        "outputId": "f4ff3d01-e99f-4b93-8c0e-3eaecb2addfb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14182, 115)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# Import of data from local file\n",
        "emotion_lexicon = pd.read_excel(\"/content/drive/My Drive/data/NRC-Emotion-Lexicon-v0.92-In105Languages-Nov2017Translations.xlsx\", sheet_name=\"NRC-Lex-v0.92-word-translations\")\n",
        "# Printing number of rows and columns in emotion lexicon\n",
        "emotion_lexicon.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "6b8cba42",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6b8cba42",
        "outputId": "18b7e066-5917-45b5-df16-d53b7111bcdb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['English (en)', 'Afrikaans (af)', 'Albanian (sq)', 'Amharic (am)',\n",
              "       'Arabic (ar)', 'Armenian (hy)', 'Azeerbaijani (az)', 'Basque (eu)',\n",
              "       'Belarusian (be)', 'Bengali (bn)',\n",
              "       ...\n",
              "       'Positive', 'Negative', 'Anger', 'Anticipation', 'Disgust', 'Fear',\n",
              "       'Joy', 'Sadness', 'Surprise', 'Trust'],\n",
              "      dtype='object', length=115)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# Printing columns from the dataset\n",
        "emotion_lexicon.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e915517a",
      "metadata": {
        "id": "e915517a"
      },
      "source": [
        "# Word2Vec embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "6d30ed23",
      "metadata": {
        "id": "6d30ed23"
      },
      "outputs": [],
      "source": [
        "# Import of fine tuned word2vec model\n",
        "model_path_SG = \"/content/drive/My Drive/fine_tuned_word2vec_sg/fine_tuned_word2vec_sg.model\"\n",
        "model_path_CBOW = \"/content/drive/My Drive/fine_tuned_word2vec_cbow/fine_tuned_word2vec_cbow.model\"\n",
        "word2vec_model_SG = Word2Vec.load(model_path_SG)\n",
        "word2vec_model_CBOW = Word2Vec.load(model_path_CBOW)\n",
        "\n",
        "embedding_dim_SG = word2vec_model_SG.vector_size\n",
        "embedding_dim_CBOW = word2vec_model_CBOW.vector_size"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c764ea2d",
      "metadata": {
        "id": "c764ea2d"
      },
      "source": [
        "Checking the coverage of words from emotion lexicon by word2vec model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "452e5002",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "452e5002",
        "outputId": "eefaf54a-2ec2-430b-916e-e1ce8042ba7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lexicon coverage: 87.17%\n",
            "Covered words: 12362\n"
          ]
        }
      ],
      "source": [
        "# Coverage of emotion lexicon words in word2vec vocabulary for SG model\n",
        "lexicon_words = set(emotion_lexicon[\"English (en)\"])\n",
        "word2vec_vocab_SG = set(word2vec_model_SG.wv.key_to_index.keys())\n",
        "\n",
        "covered_words = lexicon_words & word2vec_vocab_SG # Intersection of lexicon words and word2vec vocabulary\n",
        "coverage_percentage = len(covered_words) / len(lexicon_words) * 100\n",
        "\n",
        "print(f\"Lexicon coverage: {coverage_percentage:.2f}%\")\n",
        "print(f\"Covered words: {len(covered_words)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "ad47906c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ad47906c",
        "outputId": "0634f575-476f-44aa-f507-0b9863227c03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lexicon coverage: 87.17%\n",
            "Covered words: 12362\n"
          ]
        }
      ],
      "source": [
        "# Coverage of emotion lexicon words in word2vec vocabulary for CBOW model\n",
        "word2vec_vocab_CBOW = set(word2vec_model_CBOW.wv.key_to_index.keys())\n",
        "\n",
        "covered_words = lexicon_words & word2vec_vocab_CBOW # Intersection of lexicon words and word2vec vocabulary\n",
        "coverage_percentage = len(covered_words) / len(lexicon_words) * 100\n",
        "\n",
        "print(f\"Lexicon coverage: {coverage_percentage:.2f}%\")\n",
        "print(f\"Covered words: {len(covered_words)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "55f1f8e6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55f1f8e6",
        "outputId": "fa7022e2-f4b4-4302-81d1-d9f802cfc894"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Covered words: 12362\n"
          ]
        }
      ],
      "source": [
        "# Intersection of lexicon words and word2vec vocabulary\n",
        "intersection = word2vec_vocab_SG & word2vec_vocab_CBOW & lexicon_words\n",
        "print(f\"Covered words: {len(intersection)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31a8e58f",
      "metadata": {
        "id": "31a8e58f"
      },
      "source": [
        "Filtering only covered words and columns; word, anger, joy, sadness, disgust, surprise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "f1b645da",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "f1b645da",
        "outputId": "68e993b9-02c9-4e59-e542-e0fd87e987c5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  English (en)  Anger  Joy  Sadness  Disgust  Surprise\n",
              "0        aback      0    0        0        0         0\n",
              "1      abandon      0    0        1        0         0\n",
              "2    abandoned      1    0        1        0         0\n",
              "3  abandonment      1    0        1        0         1\n",
              "4        abate      0    0        0        0         0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e38f653b-63bf-46ba-bd5e-cda0e028f2b5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>English (en)</th>\n",
              "      <th>Anger</th>\n",
              "      <th>Joy</th>\n",
              "      <th>Sadness</th>\n",
              "      <th>Disgust</th>\n",
              "      <th>Surprise</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>aback</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>abandon</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>abandoned</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>abandonment</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>abate</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e38f653b-63bf-46ba-bd5e-cda0e028f2b5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e38f653b-63bf-46ba-bd5e-cda0e028f2b5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e38f653b-63bf-46ba-bd5e-cda0e028f2b5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-6242c68f-254a-4b03-bc6d-43f8194cdc3d\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6242c68f-254a-4b03-bc6d-43f8194cdc3d')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-6242c68f-254a-4b03-bc6d-43f8194cdc3d button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "filtered_lexicon",
              "summary": "{\n  \"name\": \"filtered_lexicon\",\n  \"rows\": 12362,\n  \"fields\": [\n    {\n      \"column\": \"English (en)\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 12362,\n        \"samples\": [\n          \"exterior\",\n          \"corporate\",\n          \"cot\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Anger\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Joy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sadness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Disgust\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Surprise\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "filtered_lexicon = emotion_lexicon[emotion_lexicon[\"English (en)\"].isin(word2vec_vocab_SG)].reset_index(drop=True)\n",
        "filtered_lexicon = filtered_lexicon[[\"English (en)\", \"Anger\", \"Joy\", \"Sadness\", \"Disgust\", \"Surprise\"]]\n",
        "filtered_lexicon.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "0da542d8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0da542d8",
        "outputId": "4d55a7a8-93b1-4207-f5f7-899363426205"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Number of samples per class:\n",
            "Anger\n",
            "0    11220\n",
            "1     1142\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Number of samples per class:\n",
            "Joy\n",
            "0    11698\n",
            "1      664\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Number of samples per class:\n",
            "Sadness\n",
            "0    11264\n",
            "1     1098\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Number of samples per class:\n",
            "Disgust\n",
            "0    11387\n",
            "1      975\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Number of samples per class:\n",
            "Surprise\n",
            "0    11853\n",
            "1      509\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Checking class distribution of target valuess\n",
        "for i in range (1, 6):\n",
        "    class_distribution = filtered_lexicon.iloc[:, i].value_counts()\n",
        "    print(\"\\nNumber of samples per class:\")\n",
        "    print(class_distribution)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e1e9f9b",
      "metadata": {
        "id": "9e1e9f9b"
      },
      "source": [
        "Classes are disbalanced..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "9db6fa88",
      "metadata": {
        "id": "9db6fa88"
      },
      "outputs": [],
      "source": [
        "# Function for getting word2vec embedding for an input word from lexicon\n",
        "def get_word2vec_embeddings(word, model):\n",
        "    try:\n",
        "        return model.wv[word] # Return the embedding for the word\n",
        "    except KeyError:\n",
        "        return np.zeros(model.vector_size) # Return a zero-vector if the word is not in the vocabulary (this should never be the case since we filtered lexicon already)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "24045904",
      "metadata": {
        "id": "24045904"
      },
      "outputs": [],
      "source": [
        "# Getting word2vec embeddings for each word in the sentence\n",
        "embeddings_CBOW_list = [\n",
        "    get_word2vec_embeddings(text, word2vec_model_CBOW)\n",
        "    for text in filtered_lexicon['English (en)']\n",
        "]\n",
        "\n",
        "embeddings_SG_list = [\n",
        "    get_word2vec_embeddings(text, word2vec_model_SG)\n",
        "    for text in filtered_lexicon['English (en)']\n",
        "]\n",
        "\n",
        "# Convert lists of 1D vectors to 2D NumPy arrays\n",
        "embeddings_CBOW = np.array(embeddings_CBOW_list)\n",
        "embeddings_SG = np.array(embeddings_SG_list)\n",
        "embeddings_CBOW = embeddings_CBOW[:, np.newaxis, :] # Adds a new axis for timesteps\n",
        "embeddings_SG = embeddings_SG[:, np.newaxis, :] # Adds a new axis for timesteps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "fb8b2af1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fb8b2af1",
        "outputId": "117647a3-ce5c-4d9d-afc0-a7473741f73f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of embeddings_CBOW_reshaped: (12362, 1, 300)\n",
            "Shape of embeddings_SG_reshaped: (12362, 1, 300)\n",
            "Data type of embeddings_CBOW_reshaped: float32\n"
          ]
        }
      ],
      "source": [
        "# Checking the dimensions of the embeddings\n",
        "print(f\"Shape of embeddings_CBOW_reshaped: {embeddings_CBOW.shape}\")\n",
        "print(f\"Shape of embeddings_SG_reshaped: {embeddings_SG.shape}\")\n",
        "print(f\"Data type of embeddings_CBOW_reshaped: {embeddings_CBOW.dtype}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57d162fe",
      "metadata": {
        "id": "57d162fe"
      },
      "source": [
        "# RNN Predictions for Word2Vec Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72533196",
      "metadata": {
        "id": "72533196"
      },
      "source": [
        "### Predictions for SG embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "66ec0e83",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66ec0e83",
        "outputId": "a0f969d8-f9d2-4fd8-eccc-63495763433d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Training a model for emotion: Anger ---\n",
            "  --- Fold 1/5 ---\n",
            "    Fold 1 - Loss: 0.2589, Accuracy: 0.9131, Precision: 0.6842, Recall: 0.1135, F1-Score: 0.1948, ROC AUC: 0.7845\n",
            "  --- Fold 2/5 ---\n",
            "    Fold 2 - Loss: 0.2684, Accuracy: 0.9139, Precision: 0.6212, Recall: 0.1790, F1-Score: 0.2780, ROC AUC: 0.7730\n",
            "  --- Fold 3/5 ---\n",
            "    Fold 3 - Loss: 0.2733, Accuracy: 0.9134, Precision: 0.6842, Recall: 0.1140, F1-Score: 0.1955, ROC AUC: 0.7483\n",
            "  --- Fold 4/5 ---\n",
            "    Fold 4 - Loss: 0.2800, Accuracy: 0.9114, Precision: 0.8462, Recall: 0.0482, F1-Score: 0.0913, ROC AUC: 0.7375\n",
            "  --- Fold 5/5 ---\n",
            "    Fold 5 - Loss: 0.2689, Accuracy: 0.9126, Precision: 0.7500, Recall: 0.0789, F1-Score: 0.1429, ROC AUC: 0.7455\n",
            "\n",
            "--- Training a model for emotion: Joy ---\n",
            "  --- Fold 1/5 ---\n",
            "    Fold 1 - Loss: 0.1697, Accuracy: 0.9507, Precision: 0.7895, Recall: 0.1128, F1-Score: 0.1974, ROC AUC: 0.8001\n",
            "  --- Fold 2/5 ---\n",
            "    Fold 2 - Loss: 0.1972, Accuracy: 0.9503, Precision: 0.7500, Recall: 0.1128, F1-Score: 0.1961, ROC AUC: 0.7685\n",
            "  --- Fold 3/5 ---\n",
            "    Fold 3 - Loss: 0.1659, Accuracy: 0.9498, Precision: 0.6538, Recall: 0.1288, F1-Score: 0.2152, ROC AUC: 0.8250\n",
            "  --- Fold 4/5 ---\n",
            "    Fold 4 - Loss: 0.1714, Accuracy: 0.9494, Precision: 0.7222, Recall: 0.0977, F1-Score: 0.1722, ROC AUC: 0.8020\n",
            "  --- Fold 5/5 ---\n",
            "    Fold 5 - Loss: 0.1724, Accuracy: 0.9539, Precision: 0.8800, Recall: 0.1654, F1-Score: 0.2785, ROC AUC: 0.7829\n"
          ]
        }
      ],
      "source": [
        "# 5-fold cross validation using Bidirectional LSTM RNN\n",
        "# Model parameters\n",
        "n_splits = 5 # 5-fold cross-validation\n",
        "epochs = 50\n",
        "batch_size = 16\n",
        "lstm_units = 128\n",
        "dropout_rate = 0.3\n",
        "\n",
        "emotion_columns = ['Anger', 'Joy'] # column names\n",
        "all_emotions_results_SG = {}\n",
        "\n",
        "for emotion_column_name in emotion_columns:\n",
        "    print(f\"\\n--- Training a model for emotion: {emotion_column_name} ---\")\n",
        "\n",
        "    y_binary = filtered_lexicon[emotion_column_name].values\n",
        "\n",
        "    # Initialize list to store results for individual folds of this emotion\n",
        "    emotion_fold_results = []\n",
        "\n",
        "    # StratifiedKFold initialization\n",
        "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "    # nside loop: 5-fold cross-validation\n",
        "    for fold, (train_index, val_index) in enumerate(skf.split(embeddings_SG, y_binary)):\n",
        "        print(f\"  --- Fold {fold + 1}/{n_splits} ---\")\n",
        "\n",
        "        # Splitting data to train and validation sets for the current fold\n",
        "        X_train_fold, X_val_fold = embeddings_SG[train_index], embeddings_SG[val_index]\n",
        "        y_train_fold, y_val_fold = y_binary[train_index], y_binary[val_index]\n",
        "\n",
        "        clear_session() # Reseting Keras session to build new model\n",
        "\n",
        "        # Building an LSTM Bidirectional model\n",
        "        model = Sequential()\n",
        "        model.add(Input(shape=(1, embedding_dim_SG)))\n",
        "        model.add(Bidirectional(LSTM(lstm_units, return_sequences=False)))\n",
        "        model.add(Dropout(dropout_rate))\n",
        "        model.add(Dense(64, activation='relu'))\n",
        "        model.add(Dropout(dropout_rate))\n",
        "        model.add(Dense(1, activation='sigmoid')) # 1 neuoron for binary classification (sigmoid activation)\n",
        "\n",
        "        # Model compilation for binary classification\n",
        "        model.compile(\n",
        "            optimizer='adam',\n",
        "            loss='binary_crossentropy',\n",
        "            metrics=['accuracy']\n",
        "        )\n",
        "\n",
        "        # Early Stopping callback\n",
        "        early_stopping_callback = EarlyStopping(\n",
        "            monitor='val_accuracy',\n",
        "            patience=5,\n",
        "            restore_best_weights=True,\n",
        "            verbose=0\n",
        "        )\n",
        "\n",
        "        # Training the model\n",
        "        history = model.fit(\n",
        "            X_train_fold, y_train_fold,\n",
        "            epochs=epochs,\n",
        "            batch_size=batch_size,\n",
        "            validation_data=(X_val_fold, y_val_fold),\n",
        "            callbacks=[early_stopping_callback],\n",
        "            verbose=0\n",
        "        )\n",
        "\n",
        "        # Evaluating the model\n",
        "        loss, accuracy = model.evaluate(X_val_fold, y_val_fold, verbose=0)\n",
        "\n",
        "        # Getting predictions\n",
        "        y_pred_proba = model.predict(X_val_fold, verbose=0)\n",
        "        y_pred = (y_pred_proba > 0.5).astype(int) # Binary prediction (0 ili 1)\n",
        "\n",
        "        # Calculating metrics, with zero_division=0 to handle division by zero cases\n",
        "        precision = precision_score(y_val_fold, y_pred, zero_division=0)\n",
        "        recall = recall_score(y_val_fold, y_pred, zero_division=0)\n",
        "        f1 = f1_score(y_val_fold, y_pred, zero_division=0)\n",
        "\n",
        "        if len(np.unique(y_val_fold)) < 2: # Cannot calculate if validation set doesn't have both classes\n",
        "            roc_auc = np.nan\n",
        "        else:\n",
        "            roc_auc = roc_auc_score(y_val_fold, y_pred_proba) # Use probabilities for ROC AUC\n",
        "\n",
        "        print(f\"    Fold {fold + 1} - Loss: {loss:.4f}, Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1-Score: {f1:.4f}, ROC AUC: {roc_auc:.4f}\")\n",
        "\n",
        "        # Store results for the current fold\n",
        "        emotion_fold_results.append({\n",
        "            'fold': fold + 1,\n",
        "            'loss': loss,\n",
        "            'accuracy': accuracy,\n",
        "            'precision': precision,\n",
        "            'recall': recall,\n",
        "            'f1_score': f1,\n",
        "            'roc_auc': roc_auc\n",
        "        })\n",
        "\n",
        "    # Store all fold results for the current emotion\n",
        "    all_emotions_results_SG[emotion_column_name] = emotion_fold_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "0df30949",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0df30949",
        "outputId": "1739ea54-8384-4fb9-fc4b-5c1f2e94e8cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Results for emotion: Anger\n",
            "  Accuracy:  0.9129 +/- 0.0008\n",
            "  Precision: 0.7172 +/- 0.0763\n",
            "  Recall:    0.1068 +/- 0.0436\n",
            "  F1-Score:  0.1805 +/- 0.0621\n",
            "  ROC AUC:   0.7578 +/- 0.0179\n",
            "------------------------------\n",
            "\n",
            "Results for emotion: Joy\n",
            "  Accuracy:  0.9508 +/- 0.0016\n",
            "  Precision: 0.7591 +/- 0.0749\n",
            "  Recall:    0.1235 +/- 0.0231\n",
            "  F1-Score:  0.2119 +/- 0.0360\n",
            "  ROC AUC:   0.7957 +/- 0.0191\n",
            "------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Calculating and printing the average results for each emotion across all folds\n",
        "for emotion, fold_results_list in all_emotions_results_SG.items():\n",
        "    print(f\"\\nResults for emotion: {emotion}\")\n",
        "\n",
        "    accuracies = []\n",
        "    precisions = []\n",
        "    recalls = []\n",
        "    f1_scores = []\n",
        "    roc_aucs = []\n",
        "\n",
        "    for result_dict in fold_results_list:\n",
        "        accuracies.append(result_dict['accuracy'])\n",
        "        precisions.append(result_dict['precision'])\n",
        "        recalls.append(result_dict['recall'])\n",
        "        f1_scores.append(result_dict['f1_score'])\n",
        "        roc_aucs.append(result_dict['roc_auc'])\n",
        "\n",
        "    # Calculate mean and standard deviation for each metric\n",
        "    avg_accuracy = np.mean(accuracies)\n",
        "    std_accuracy = np.std(accuracies)\n",
        "\n",
        "    avg_precision = np.mean(precisions)\n",
        "    std_precision = np.std(precisions)\n",
        "\n",
        "    avg_recall = np.mean(recalls)\n",
        "    std_recall = np.std(recalls)\n",
        "\n",
        "    avg_f1_score = np.mean(f1_scores)\n",
        "    std_f1_score = np.std(f1_scores)\n",
        "\n",
        "    avg_roc_auc = np.nanmean(roc_aucs)\n",
        "    std_roc_auc = np.nanstd(roc_aucs)\n",
        "\n",
        "    print(f\"  Accuracy:  {avg_accuracy:.4f} +/- {std_accuracy:.4f}\")\n",
        "    print(f\"  Precision: {avg_precision:.4f} +/- {std_precision:.4f}\")\n",
        "    print(f\"  Recall:    {avg_recall:.4f} +/- {std_recall:.4f}\")\n",
        "    print(f\"  F1-Score:  {avg_f1_score:.4f} +/- {std_f1_score:.4f}\")\n",
        "\n",
        "    if not np.isnan(avg_roc_auc):\n",
        "        print(f\"  ROC AUC:   {avg_roc_auc:.4f} +/- {std_roc_auc:.4f}\")\n",
        "    else:\n",
        "        print(\"  ROC AUC:   N/A (not enough classes in validation folds)\")\n",
        "\n",
        "    print(\"-\" * 30)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d62ab553",
      "metadata": {
        "id": "d62ab553"
      },
      "source": [
        "### Predictions for CBOW embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "ad8cd4de",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ad8cd4de",
        "outputId": "da3c9bd3-f4d7-4e54-d63e-369168733f75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Training a model for emotion: Anger ---\n",
            "  --- Fold 1/5 ---\n",
            "    Fold 1 - Loss: 0.2837, Accuracy: 0.9106, Precision: 0.6000, Recall: 0.1048, F1-Score: 0.1784, ROC AUC: 0.7354\n",
            "  --- Fold 2/5 ---\n",
            "    Fold 2 - Loss: 0.2773, Accuracy: 0.9114, Precision: 0.6087, Recall: 0.1223, F1-Score: 0.2036, ROC AUC: 0.7455\n",
            "  --- Fold 3/5 ---\n",
            "    Fold 3 - Loss: 0.2881, Accuracy: 0.9118, Precision: 0.8125, Recall: 0.0570, F1-Score: 0.1066, ROC AUC: 0.7346\n",
            "  --- Fold 4/5 ---\n",
            "    Fold 4 - Loss: 0.2815, Accuracy: 0.9086, Precision: 0.5556, Recall: 0.0439, F1-Score: 0.0813, ROC AUC: 0.7398\n",
            "  --- Fold 5/5 ---\n",
            "    Fold 5 - Loss: 0.2846, Accuracy: 0.9094, Precision: 0.5588, Recall: 0.0833, F1-Score: 0.1450, ROC AUC: 0.7374\n",
            "\n",
            "--- Training a model for emotion: Joy ---\n",
            "  --- Fold 1/5 ---\n",
            "    Fold 1 - Loss: 0.1760, Accuracy: 0.9486, Precision: 0.6154, Recall: 0.1203, F1-Score: 0.2013, ROC AUC: 0.7794\n",
            "  --- Fold 2/5 ---\n",
            "    Fold 2 - Loss: 0.2300, Accuracy: 0.9486, Precision: 0.6071, Recall: 0.1278, F1-Score: 0.2112, ROC AUC: 0.7381\n",
            "  --- Fold 3/5 ---\n",
            "    Fold 3 - Loss: 0.1984, Accuracy: 0.9506, Precision: 0.6667, Recall: 0.1515, F1-Score: 0.2469, ROC AUC: 0.7897\n",
            "  --- Fold 4/5 ---\n",
            "    Fold 4 - Loss: 0.1810, Accuracy: 0.9474, Precision: 0.5455, Recall: 0.1353, F1-Score: 0.2169, ROC AUC: 0.7820\n",
            "  --- Fold 5/5 ---\n",
            "    Fold 5 - Loss: 0.1860, Accuracy: 0.9523, Precision: 0.6596, Recall: 0.2331, F1-Score: 0.3444, ROC AUC: 0.7725\n"
          ]
        }
      ],
      "source": [
        "# 5-fold cross validation using Bidirectional LSTM RNN\n",
        "# Model parameters\n",
        "n_splits = 5 # 5-fold cross-validation\n",
        "epochs = 50\n",
        "batch_size = 16\n",
        "lstm_units = 128\n",
        "dropout_rate = 0.3\n",
        "\n",
        "emotion_columns = ['Anger', 'Joy'] # column names\n",
        "all_emotions_results_CBOW = {}\n",
        "\n",
        "for emotion_column_name in emotion_columns:\n",
        "    print(f\"\\n--- Training a model for emotion: {emotion_column_name} ---\")\n",
        "\n",
        "    y_binary = filtered_lexicon[emotion_column_name].values\n",
        "\n",
        "    # Initialize list to store results for individual folds of this emotion\n",
        "    emotion_fold_results = []\n",
        "\n",
        "    # StratifiedKFold initialization\n",
        "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "    # nside loop: 5-fold cross-validation\n",
        "    for fold, (train_index, val_index) in enumerate(skf.split(embeddings_CBOW, y_binary)):\n",
        "        print(f\"  --- Fold {fold + 1}/{n_splits} ---\")\n",
        "\n",
        "        # Splitting data to train and validation sets for the current fold\n",
        "        X_train_fold, X_val_fold = embeddings_CBOW[train_index], embeddings_CBOW[val_index]\n",
        "        y_train_fold, y_val_fold = y_binary[train_index], y_binary[val_index]\n",
        "\n",
        "        clear_session() # Reseting Keras session to build new model\n",
        "\n",
        "        # Building an LSTM Bidirectional model\n",
        "        model = Sequential()\n",
        "        model.add(Input(shape=(1, embedding_dim_CBOW)))\n",
        "        model.add(Bidirectional(LSTM(lstm_units, return_sequences=False)))\n",
        "        model.add(Dropout(dropout_rate))\n",
        "        model.add(Dense(64, activation='relu'))\n",
        "        model.add(Dropout(dropout_rate))\n",
        "        model.add(Dense(1, activation='sigmoid')) # 1 neuoron for binary classification (sigmoid activation)\n",
        "\n",
        "        # Model compilation for binary classification\n",
        "        model.compile(\n",
        "            optimizer='adam',\n",
        "            loss='binary_crossentropy',\n",
        "            metrics=['accuracy']\n",
        "        )\n",
        "\n",
        "        # Early Stopping callback\n",
        "        early_stopping_callback = EarlyStopping(\n",
        "            monitor='val_accuracy',\n",
        "            patience=5,\n",
        "            restore_best_weights=True,\n",
        "            verbose=0\n",
        "        )\n",
        "\n",
        "        # Training the model\n",
        "        history = model.fit(\n",
        "            X_train_fold, y_train_fold,\n",
        "            epochs=epochs,\n",
        "            batch_size=batch_size,\n",
        "            validation_data=(X_val_fold, y_val_fold),\n",
        "            callbacks=[early_stopping_callback],\n",
        "            verbose=0\n",
        "        )\n",
        "\n",
        "        # Evaluating the model\n",
        "        loss, accuracy = model.evaluate(X_val_fold, y_val_fold, verbose=0)\n",
        "\n",
        "        # Getting predictions\n",
        "        y_pred_proba = model.predict(X_val_fold, verbose=0)\n",
        "        y_pred = (y_pred_proba > 0.5).astype(int) # Binary prediction (0 ili 1)\n",
        "\n",
        "        # Calculating metrics, with zero_division=0 to handle division by zero cases\n",
        "        precision = precision_score(y_val_fold, y_pred, zero_division=0)\n",
        "        recall = recall_score(y_val_fold, y_pred, zero_division=0)\n",
        "        f1 = f1_score(y_val_fold, y_pred, zero_division=0)\n",
        "\n",
        "        if len(np.unique(y_val_fold)) < 2: # Cannot calculate if validation set doesn't have both classes\n",
        "            roc_auc = np.nan\n",
        "        else:\n",
        "            roc_auc = roc_auc_score(y_val_fold, y_pred_proba) # Use probabilities for ROC AUC\n",
        "\n",
        "        print(f\"    Fold {fold + 1} - Loss: {loss:.4f}, Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1-Score: {f1:.4f}, ROC AUC: {roc_auc:.4f}\")\n",
        "\n",
        "        # Store results for the current fold\n",
        "        emotion_fold_results.append({\n",
        "            'fold': fold + 1,\n",
        "            'loss': loss,\n",
        "            'accuracy': accuracy,\n",
        "            'precision': precision,\n",
        "            'recall': recall,\n",
        "            'f1_score': f1,\n",
        "            'roc_auc': roc_auc\n",
        "        })\n",
        "\n",
        "    # Store all fold results for the current emotion\n",
        "    all_emotions_results_CBOW[emotion_column_name] = emotion_fold_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "1d7c324f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1d7c324f",
        "outputId": "1e326be0-c93b-4e42-f280-8fc51f7e57fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Results for emotion: Anger\n",
            "  Accuracy:  0.9104 +/- 0.0012\n",
            "  Precision: 0.6271 +/- 0.0951\n",
            "  Recall:    0.0823 +/- 0.0291\n",
            "  F1-Score:  0.1430 +/- 0.0449\n",
            "  ROC AUC:   0.7385 +/- 0.0039\n",
            "------------------------------\n",
            "\n",
            "Results for emotion: Joy\n",
            "  Accuracy:  0.9495 +/- 0.0017\n",
            "  Precision: 0.6188 +/- 0.0435\n",
            "  Recall:    0.1536 +/- 0.0411\n",
            "  F1-Score:  0.2441 +/- 0.0524\n",
            "  ROC AUC:   0.7723 +/- 0.0180\n",
            "------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Calculating and printing the average results for each emotion across all folds\n",
        "for emotion, fold_results_list in all_emotions_results_CBOW.items():\n",
        "    print(f\"\\nResults for emotion: {emotion}\")\n",
        "\n",
        "    accuracies = []\n",
        "    precisions = []\n",
        "    recalls = []\n",
        "    f1_scores = []\n",
        "    roc_aucs = []\n",
        "\n",
        "    for result_dict in fold_results_list:\n",
        "        accuracies.append(result_dict['accuracy'])\n",
        "        precisions.append(result_dict['precision'])\n",
        "        recalls.append(result_dict['recall'])\n",
        "        f1_scores.append(result_dict['f1_score'])\n",
        "        roc_aucs.append(result_dict['roc_auc'])\n",
        "\n",
        "    # Calculate mean and standard deviation for each metric\n",
        "    avg_accuracy = np.mean(accuracies)\n",
        "    std_accuracy = np.std(accuracies)\n",
        "\n",
        "    avg_precision = np.mean(precisions)\n",
        "    std_precision = np.std(precisions)\n",
        "\n",
        "    avg_recall = np.mean(recalls)\n",
        "    std_recall = np.std(recalls)\n",
        "\n",
        "    avg_f1_score = np.mean(f1_scores)\n",
        "    std_f1_score = np.std(f1_scores)\n",
        "\n",
        "    avg_roc_auc = np.nanmean(roc_aucs)\n",
        "    std_roc_auc = np.nanstd(roc_aucs)\n",
        "\n",
        "    print(f\"  Accuracy:  {avg_accuracy:.4f} +/- {std_accuracy:.4f}\")\n",
        "    print(f\"  Precision: {avg_precision:.4f} +/- {std_precision:.4f}\")\n",
        "    print(f\"  Recall:    {avg_recall:.4f} +/- {std_recall:.4f}\")\n",
        "    print(f\"  F1-Score:  {avg_f1_score:.4f} +/- {std_f1_score:.4f}\")\n",
        "\n",
        "    if not np.isnan(avg_roc_auc):\n",
        "        print(f\"  ROC AUC:   {avg_roc_auc:.4f} +/- {std_roc_auc:.4f}\")\n",
        "    else:\n",
        "        print(\"  ROC AUC:   N/A (not enough classes in validation folds)\")\n",
        "\n",
        "    print(\"-\" * 30)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b618ef6",
      "metadata": {
        "id": "1b618ef6"
      },
      "source": [
        "# BERT embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "1c1c053d",
      "metadata": {
        "id": "1c1c053d"
      },
      "outputs": [],
      "source": [
        "# Import of fine tuned bert model\n",
        "model_path = \"/content/drive/My Drive/fine_tuned_bert\"\n",
        "bert_tokenizer = BertTokenizer.from_pretrained(model_path)\n",
        "bert_model = BertForMaskedLM.from_pretrained(model_path)\n",
        "embedding_dim_bert = bert_model.config.hidden_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "f96fdaba",
      "metadata": {
        "id": "f96fdaba"
      },
      "outputs": [],
      "source": [
        "# Function for getting a BERT embedding for an input word from lexicon\n",
        "def get_bert_embeddings(word, model, tokenizer):\n",
        "\n",
        "    # Tokenize word and convert to tensor\n",
        "    input_ids = tokenizer.encode(word, add_special_tokens=False, return_tensors=\"pt\")\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient computation for efficiency\n",
        "        outputs = model.bert(input_ids)  # Extract only transformer layers, ignoring MLM head\n",
        "        last_hidden_state = outputs.last_hidden_state  # Get hidden state of the last layer\n",
        "\n",
        "    # Calculate the average embedding across tokens\n",
        "    word_embedding = last_hidden_state.mean(dim=1).squeeze().numpy()\n",
        "\n",
        "    return word_embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "d3756e2e",
      "metadata": {
        "id": "d3756e2e"
      },
      "outputs": [],
      "source": [
        "# Getting word2vec embeddings for each word in the sentence (except stowords)\n",
        "embeddings_BERT_list = [\n",
        "    get_bert_embeddings(word, bert_model, bert_tokenizer)\n",
        "    for word in filtered_lexicon['English (en)']\n",
        "]\n",
        "\n",
        "\n",
        "# Convert lists of 1D vectors to 2D NumPy arrays suitable for RNN\n",
        "embeddings_BERT= np.array(embeddings_BERT_list)\n",
        "embeddings_BERT = embeddings_BERT[:, np.newaxis, :] # Adds a new axis for timesteps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "71cd643d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71cd643d",
        "outputId": "0c2187eb-e35e-4d0b-c32a-c8437b06b090"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding dimension of BERT: 768\n",
            "Shape of embeddings_BERT: (12362, 1, 768)\n",
            "Data type of embeddings_BERT: float32\n"
          ]
        }
      ],
      "source": [
        "print(f\"Embedding dimension of BERT: {embedding_dim_bert}\")\n",
        "print(f\"Shape of embeddings_BERT: {embeddings_BERT.shape}\")\n",
        "print(f\"Data type of embeddings_BERT: {embeddings_BERT.dtype}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d714da1",
      "metadata": {
        "id": "0d714da1"
      },
      "source": [
        "# RNN Predictions for Bert Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "f6b3341c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6b3341c",
        "outputId": "dfb7209b-b9fe-4c04-f3d1-c17c19898947"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Training a model for emotion: Anger ---\n",
            "  --- Fold 1/5 ---\n",
            "    Fold 1 - Loss: 0.2785, Accuracy: 0.9106, Precision: 1.0000, Recall: 0.0349, F1-Score: 0.0675, ROC AUC: 0.7182\n",
            "  --- Fold 2/5 ---\n",
            "    Fold 2 - Loss: 0.2830, Accuracy: 0.9102, Precision: 0.6400, Recall: 0.0699, F1-Score: 0.1260, ROC AUC: 0.7198\n",
            "  --- Fold 3/5 ---\n",
            "    Fold 3 - Loss: 0.2861, Accuracy: 0.9142, Precision: 0.8077, Recall: 0.0921, F1-Score: 0.1654, ROC AUC: 0.7155\n",
            "  --- Fold 4/5 ---\n",
            "    Fold 4 - Loss: 0.2873, Accuracy: 0.9114, Precision: 0.7368, Recall: 0.0614, F1-Score: 0.1134, ROC AUC: 0.7275\n",
            "  --- Fold 5/5 ---\n",
            "    Fold 5 - Loss: 0.2838, Accuracy: 0.9082, Precision: 0.5714, Recall: 0.0175, F1-Score: 0.0340, ROC AUC: 0.7173\n",
            "\n",
            "--- Training a model for emotion: Joy ---\n",
            "  --- Fold 1/5 ---\n",
            "    Fold 1 - Loss: 0.2001, Accuracy: 0.9474, Precision: 0.8000, Recall: 0.0301, F1-Score: 0.0580, ROC AUC: 0.6888\n",
            "  --- Fold 2/5 ---\n",
            "    Fold 2 - Loss: 0.1882, Accuracy: 0.9486, Precision: 0.8750, Recall: 0.0526, F1-Score: 0.0993, ROC AUC: 0.7313\n",
            "  --- Fold 3/5 ---\n",
            "    Fold 3 - Loss: 0.1993, Accuracy: 0.9466, Precision: 0.0000, Recall: 0.0000, F1-Score: 0.0000, ROC AUC: 0.6809\n",
            "  --- Fold 4/5 ---\n",
            "    Fold 4 - Loss: 0.1929, Accuracy: 0.9490, Precision: 0.8182, Recall: 0.0677, F1-Score: 0.1250, ROC AUC: 0.6941\n",
            "  --- Fold 5/5 ---\n",
            "    Fold 5 - Loss: 0.1945, Accuracy: 0.9466, Precision: 0.6667, Recall: 0.0150, F1-Score: 0.0294, ROC AUC: 0.7066\n"
          ]
        }
      ],
      "source": [
        "# 5-fold cross validation using Bidirectional LSTM\n",
        "# Model parameters\n",
        "n_splits = 5 # 5-fold cross-validation\n",
        "epochs = 50\n",
        "batch_size = 16\n",
        "lstm_units = 128\n",
        "dropout_rate = 0.3\n",
        "\n",
        "emotion_columns = ['Anger', 'Joy'] # column names\n",
        "all_emotions_results_BERT = {}\n",
        "\n",
        "for emotion_column_name in emotion_columns:\n",
        "    print(f\"\\n--- Training a model for emotion: {emotion_column_name} ---\")\n",
        "\n",
        "    y_binary = filtered_lexicon[emotion_column_name].values\n",
        "\n",
        "    # Initialize list to store results for individual folds of this emotion\n",
        "    emotion_fold_results = []\n",
        "\n",
        "    # StratifiedKFold initialization\n",
        "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "    # nside loop: 5-fold cross-validation\n",
        "    for fold, (train_index, val_index) in enumerate(skf.split(embeddings_BERT, y_binary)):\n",
        "        print(f\"  --- Fold {fold + 1}/{n_splits} ---\")\n",
        "\n",
        "        # Splitting data to train and validation sets for the current fold\n",
        "        X_train_fold, X_val_fold = embeddings_BERT[train_index], embeddings_BERT[val_index]\n",
        "        y_train_fold, y_val_fold = y_binary[train_index], y_binary[val_index]\n",
        "\n",
        "        clear_session() # Reseting Keras session to build new model\n",
        "\n",
        "        # Building an LSTM Bidirectional model\n",
        "        model = Sequential()\n",
        "        model.add(Input(shape=(1, embedding_dim_bert)))\n",
        "        model.add(Bidirectional(LSTM(lstm_units, return_sequences=False)))\n",
        "        model.add(Dropout(dropout_rate))\n",
        "        model.add(Dense(64, activation='relu'))\n",
        "        model.add(Dropout(dropout_rate))\n",
        "        model.add(Dense(1, activation='sigmoid')) # 1 neuoron for binary classification (sigmoid activation)\n",
        "\n",
        "        # Model compilation for binary classification\n",
        "        model.compile(\n",
        "            optimizer='adam',\n",
        "            loss='binary_crossentropy',\n",
        "            metrics=['accuracy']\n",
        "        )\n",
        "\n",
        "        # Early Stopping callback\n",
        "        early_stopping_callback = EarlyStopping(\n",
        "            monitor='val_accuracy',\n",
        "            patience=5,\n",
        "            restore_best_weights=True,\n",
        "            verbose=0\n",
        "        )\n",
        "\n",
        "        # Training the model\n",
        "        history = model.fit(\n",
        "            X_train_fold, y_train_fold,\n",
        "            epochs=epochs,\n",
        "            batch_size=batch_size,\n",
        "            validation_data=(X_val_fold, y_val_fold),\n",
        "            callbacks=[early_stopping_callback],\n",
        "            verbose=0\n",
        "        )\n",
        "\n",
        "        # Evaluating the model\n",
        "        loss, accuracy = model.evaluate(X_val_fold, y_val_fold, verbose=0)\n",
        "\n",
        "        # Getting predictions\n",
        "        y_pred_proba = model.predict(X_val_fold, verbose=0)\n",
        "        y_pred = (y_pred_proba > 0.5).astype(int) # Binary prediction (0 ili 1)\n",
        "\n",
        "        # Calculating metrics, with zero_division=0 to handle division by zero cases\n",
        "        precision = precision_score(y_val_fold, y_pred, zero_division=0)\n",
        "        recall = recall_score(y_val_fold, y_pred, zero_division=0)\n",
        "        f1 = f1_score(y_val_fold, y_pred, zero_division=0)\n",
        "\n",
        "        if len(np.unique(y_val_fold)) < 2: # Cannot calculate if validation set doesn't have both classes\n",
        "            roc_auc = np.nan\n",
        "        else:\n",
        "            roc_auc = roc_auc_score(y_val_fold, y_pred_proba) # Use probabilities for ROC AUC\n",
        "\n",
        "        print(f\"    Fold {fold + 1} - Loss: {loss:.4f}, Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1-Score: {f1:.4f}, ROC AUC: {roc_auc:.4f}\")\n",
        "\n",
        "        # Store results for the current fold\n",
        "        emotion_fold_results.append({\n",
        "            'fold': fold + 1,\n",
        "            'loss': loss,\n",
        "            'accuracy': accuracy,\n",
        "            'precision': precision,\n",
        "            'recall': recall,\n",
        "            'f1_score': f1,\n",
        "            'roc_auc': roc_auc\n",
        "        })\n",
        "\n",
        "    # Store all fold results for the current emotion\n",
        "    all_emotions_results_BERT[emotion_column_name] = emotion_fold_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "22142886",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22142886",
        "outputId": "73c8cbd4-a0eb-4726-e9ee-cde357d6bc37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Results for emotion: Anger\n",
            "  Accuracy:  0.9109 +/- 0.0020\n",
            "  Precision: 0.7512 +/- 0.1483\n",
            "  Recall:    0.0552 +/- 0.0262\n",
            "  F1-Score:  0.1013 +/- 0.0459\n",
            "  ROC AUC:   0.7197 +/- 0.0041\n",
            "------------------------------\n",
            "\n",
            "Results for emotion: Joy\n",
            "  Accuracy:  0.9477 +/- 0.0010\n",
            "  Precision: 0.6320 +/- 0.3233\n",
            "  Recall:    0.0331 +/- 0.0245\n",
            "  F1-Score:  0.0623 +/- 0.0453\n",
            "  ROC AUC:   0.7003 +/- 0.0176\n",
            "------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Calculating and printing the average results for each emotion across all folds\n",
        "for emotion, fold_results_list in all_emotions_results_BERT.items():\n",
        "    print(f\"\\nResults for emotion: {emotion}\")\n",
        "\n",
        "    accuracies = []\n",
        "    precisions = []\n",
        "    recalls = []\n",
        "    f1_scores = []\n",
        "    roc_aucs = []\n",
        "\n",
        "    for result_dict in fold_results_list:\n",
        "        accuracies.append(result_dict['accuracy'])\n",
        "        precisions.append(result_dict['precision'])\n",
        "        recalls.append(result_dict['recall'])\n",
        "        f1_scores.append(result_dict['f1_score'])\n",
        "        roc_aucs.append(result_dict['roc_auc'])\n",
        "\n",
        "    # Calculate mean and standard deviation for each metric\n",
        "    avg_accuracy = np.mean(accuracies)\n",
        "    std_accuracy = np.std(accuracies)\n",
        "\n",
        "    avg_precision = np.mean(precisions)\n",
        "    std_precision = np.std(precisions)\n",
        "\n",
        "    avg_recall = np.mean(recalls)\n",
        "    std_recall = np.std(recalls)\n",
        "\n",
        "    avg_f1_score = np.mean(f1_scores)\n",
        "    std_f1_score = np.std(f1_scores)\n",
        "\n",
        "    avg_roc_auc = np.nanmean(roc_aucs)\n",
        "    std_roc_auc = np.nanstd(roc_aucs)\n",
        "\n",
        "    print(f\"  Accuracy:  {avg_accuracy:.4f} +/- {std_accuracy:.4f}\")\n",
        "    print(f\"  Precision: {avg_precision:.4f} +/- {std_precision:.4f}\")\n",
        "    print(f\"  Recall:    {avg_recall:.4f} +/- {std_recall:.4f}\")\n",
        "    print(f\"  F1-Score:  {avg_f1_score:.4f} +/- {std_f1_score:.4f}\")\n",
        "\n",
        "    if not np.isnan(avg_roc_auc):\n",
        "        print(f\"  ROC AUC:   {avg_roc_auc:.4f} +/- {std_roc_auc:.4f}\")\n",
        "    else:\n",
        "        print(\"  ROC AUC:   N/A (not enough classes in validation folds)\")\n",
        "\n",
        "    print(\"-\" * 30)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}