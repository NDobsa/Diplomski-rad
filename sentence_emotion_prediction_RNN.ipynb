{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d75a2204",
      "metadata": {
        "id": "d75a2204"
      },
      "source": [
        "**Nina Dob≈°a, 28.7.2025.**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0223b1ba",
      "metadata": {
        "id": "0223b1ba"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install gensim"
      ],
      "metadata": {
        "id": "tbjNkI41tKAP"
      },
      "id": "tbjNkI41tKAP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "628333b4",
      "metadata": {
        "id": "628333b4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional, Input\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.backend import clear_session\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from gensim.models import Word2Vec\n",
        "from transformers import BertTokenizer, BertForMaskedLM\n",
        "import torch\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking how much RAM memory do we have\n",
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hm6NEY1eywGL",
        "outputId": "3f5b81ea-a8fd-4373-ffb2-8ec73643cb23"
      },
      "id": "Hm6NEY1eywGL",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 54.8 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking if we're using GPU\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYBjAWEZyv3J",
        "outputId": "c271dc50-59ed-4c8e-c813-fab701add787"
      },
      "id": "EYBjAWEZyv3J",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Jul 27 21:30:52 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab3895c3",
      "metadata": {
        "id": "ab3895c3"
      },
      "source": [
        "# GoEmotions dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "7a38b424",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7a38b424",
        "outputId": "f2e758a0-ed63-4121-f809-05019a3ed696"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "splits = {'train': 'simplified/train-00000-of-00001.parquet',\n",
        "          'validation': 'simplified/validation-00000-of-00001.parquet',\n",
        "          'test': 'simplified/test-00000-of-00001.parquet'}\n",
        "\n",
        "goemotions_train = pd.read_parquet(\"hf://datasets/google-research-datasets/go_emotions/\" + splits[\"train\"])\n",
        "goemotions_validation = pd.read_parquet(\"hf://datasets/google-research-datasets/go_emotions/\" + splits[\"validation\"])\n",
        "goemotions_test = pd.read_parquet(\"hf://datasets/google-research-datasets/go_emotions/\" + splits[\"test\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "a76806c6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a76806c6",
        "outputId": "3bcca782-4c10-465b-df3a-089b278ca3e0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(54263, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "goemotions_data = pd.concat([goemotions_train, goemotions_validation, goemotions_test], ignore_index=True)\n",
        "goemotions_data.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e417e888",
      "metadata": {
        "id": "e417e888"
      },
      "source": [
        "Cleaning and labeling emotions with 0 and 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "10a57d8c",
      "metadata": {
        "id": "10a57d8c"
      },
      "outputs": [],
      "source": [
        "# Mapping numbers from labels with emotions\n",
        "emotion_dictionary = { 0 : 'admiration', 1 : 'amusement', 2 : 'anger', 3 : 'annoyance', 4 : 'approval', 5 : 'caring', 6 : 'confusion', 7 : 'curiosity', 8 : 'desire',\n",
        "                      9 : 'disappointment', 10 : 'disapproval', 11 : 'disgust', 12 : 'embarrassment', 13 : 'excitement', 14 : 'fear', 15 : 'gratitude', 16 : 'grief',\n",
        "                      17 : 'joy', 18 : 'love', 19 : 'nervousness', 20 : 'optimism', 21 : 'pride', 22 : 'realization', 23 : 'relief', 24 : 'remorse', 25 : 'sadness',\n",
        "                      26 : 'surprise', 27 : 'neutral' }\n",
        "\n",
        "\n",
        "target_emotions = {'anger': 2, 'sadness': 25, 'joy': 17, 'disgust' : 11, 'surprise' : 26}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "808a471f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "808a471f",
        "outputId": "86663e44-a577-4bd1-a63e-36d2b0834b22"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  anger  sadness  joy  \\\n",
              "0  My favourite food is anything I didn't have to...      0        0    0   \n",
              "1  Now if he does off himself, everyone will thin...      0        0    0   \n",
              "2                     WHY THE FUCK IS BAYLESS ISOING      1        0    0   \n",
              "3                        To make her feel threatened      0        0    0   \n",
              "4                             Dirty Southern Wankers      0        0    0   \n",
              "\n",
              "   disgust  surprise  \n",
              "0        0         0  \n",
              "1        0         0  \n",
              "2        0         0  \n",
              "3        0         0  \n",
              "4        0         0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2b3d0266-5a25-4791-8deb-e7f838d882ed\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>anger</th>\n",
              "      <th>sadness</th>\n",
              "      <th>joy</th>\n",
              "      <th>disgust</th>\n",
              "      <th>surprise</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>My favourite food is anything I didn't have to...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Now if he does off himself, everyone will thin...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>WHY THE FUCK IS BAYLESS ISOING</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>To make her feel threatened</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Dirty Southern Wankers</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2b3d0266-5a25-4791-8deb-e7f838d882ed')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2b3d0266-5a25-4791-8deb-e7f838d882ed button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2b3d0266-5a25-4791-8deb-e7f838d882ed');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-4450b8d7-f35e-47e3-ae47-7a7980241939\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4450b8d7-f35e-47e3-ae47-7a7980241939')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-4450b8d7-f35e-47e3-ae47-7a7980241939 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "goemotions_data",
              "summary": "{\n  \"name\": \"goemotions_data\",\n  \"rows\": 54263,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 53994,\n        \"samples\": [\n          \"I also love Dallas Observer's Concert Calendar by day:\",\n          \"I don't care it's amazing there lol\",\n          \"Oops, just kidding [NAME], got you.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"anger\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sadness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"joy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"disgust\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"surprise\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# Creating new columns for each emotion (anger, joy, sadness, disgust, surprise)\n",
        "# in train, validation and test goemotion datasets\n",
        "for emotion, label in target_emotions.items():\n",
        "    goemotions_data[emotion] = goemotions_data['labels'].apply(lambda x: 1 if label in x else 0)\n",
        "\n",
        "# Dropping id and labels columns\n",
        "goemotions_data = goemotions_data.drop(columns = [\"id\", \"labels\"])\n",
        "goemotions_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "a9442817",
      "metadata": {
        "id": "a9442817",
        "outputId": "a77258d4-4d97-44aa-e086-ba9e110f0e8a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Number of samples per class:\n",
            "anger\n",
            "0    52303\n",
            "1     1960\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Number of samples per class:\n",
            "sadness\n",
            "0    52638\n",
            "1     1625\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Number of samples per class:\n",
            "joy\n",
            "0    52478\n",
            "1     1785\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Number of samples per class:\n",
            "disgust\n",
            "0    53250\n",
            "1     1013\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Number of samples per class:\n",
            "surprise\n",
            "0    52933\n",
            "1     1330\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Checking class distribution of target valuess\n",
        "for i in range (1, 6):\n",
        "    class_distribution = goemotions_data.iloc[:, i].value_counts()\n",
        "    print(\"\\nNumber of samples per class:\")\n",
        "    print(class_distribution)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eef22b89",
      "metadata": {
        "id": "eef22b89"
      },
      "source": [
        "Classes are disbalanced..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "e177da80",
      "metadata": {
        "id": "e177da80"
      },
      "outputs": [],
      "source": [
        "# Defining number of classes and length of the sequence (if the sentence is shorter padding will be added)\n",
        "num_classes = 2 # sample has the target emotion or it does not (0 or 1)\n",
        "max_sequence_length = 30"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b47f55af",
      "metadata": {
        "id": "b47f55af"
      },
      "source": [
        "# Word2vec embeddings"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Connecting with google drive where fine tuned models are stored\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "WZuJjTFQCs7Q"
      },
      "id": "WZuJjTFQCs7Q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "c9cf9b84",
      "metadata": {
        "id": "c9cf9b84"
      },
      "outputs": [],
      "source": [
        "# Import of fine tuned word2vec model\n",
        "model_path_SG = \"/content/drive/My Drive/fine_tuned_word2vec_sg/fine_tuned_word2vec_sg.model\"\n",
        "model_path_CBOW = \"/content/drive/My Drive/fine_tuned_word2vec_cbow/fine_tuned_word2vec_cbow.model\"\n",
        "word2vec_model_SG = Word2Vec.load(model_path_SG)\n",
        "word2vec_model_CBOW = Word2Vec.load(model_path_CBOW)\n",
        "\n",
        "embedding_dim_SG = word2vec_model_SG.vector_size\n",
        "embedding_dim_CBOW = word2vec_model_CBOW.vector_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "5875ce03",
      "metadata": {
        "id": "5875ce03"
      },
      "outputs": [],
      "source": [
        "# Function for getting word2vec embeddings\n",
        "def get_word2vec_embeddings(sentence, model):\n",
        "    # Tokenization\n",
        "    sentence = sentence.lower()\n",
        "    words = sentence.split()\n",
        "    word_embeddings = [model.wv[word] for word in words if word in model.wv]\n",
        "\n",
        "    if not word_embeddings:  # If no words are in the vocabulary, return a zero vector\n",
        "        return []\n",
        "\n",
        "    return word_embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "a1b1ed58",
      "metadata": {
        "id": "a1b1ed58"
      },
      "outputs": [],
      "source": [
        "# Getting word2vec embeddings for each word in the sentence (except stowords)\n",
        "list_of_embeddings_CBOW = [\n",
        "   get_word2vec_embeddings(text, word2vec_model_CBOW)\n",
        "    for text in goemotions_data['text']\n",
        "]\n",
        "\n",
        "list_of_embeddings_SG = [\n",
        "   get_word2vec_embeddings(text, word2vec_model_SG)\n",
        "    for text in goemotions_data['text']\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "481bade2",
      "metadata": {
        "id": "481bade2",
        "outputId": "a33783dd-3e39-4db5-be63-43eed0b03d0a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[-0.4407    1.928     0.327    ...  0.015305 -1.564     0.739   ]\n",
            "  [-0.1677    0.0437   -0.1992   ... -0.2135    0.579     0.1512  ]\n",
            "  [ 0.1854    0.0452   -1.002    ... -1.923    -0.3738   -0.5596  ]\n",
            "  ...\n",
            "  [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
            "  [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
            "  [ 0.        0.        0.       ...  0.        0.        0.      ]]\n",
            "\n",
            " [[-0.448    -0.2402    2.35     ...  1.032    -1.137     0.7905  ]\n",
            "  [-0.554     0.1405    0.4563   ... -0.6997   -0.00902   0.4053  ]\n",
            "  [-0.3103    0.6895    1.6875   ... -1.312     1.014    -1.18    ]\n",
            "  ...\n",
            "  [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
            "  [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
            "  [ 0.        0.        0.       ...  0.        0.        0.      ]]\n",
            "\n",
            " [[-0.6646   -0.169     1.161    ...  1.207     0.37      0.3103  ]\n",
            "  [ 0.1564    0.6187    0.5796   ...  0.0896    0.925     0.6357  ]\n",
            "  [-0.1267    0.393    -0.5347   ... -0.4858    0.3386    0.696   ]\n",
            "  ...\n",
            "  [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
            "  [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
            "  [ 0.        0.        0.       ...  0.        0.        0.      ]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.1007    0.3608   -0.2566   ... -0.169    -0.004482 -0.007797]\n",
            "  [ 0.103     0.253     0.859    ... -1.032     0.3718    0.2021  ]\n",
            "  [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
            "  ...\n",
            "  [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
            "  [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
            "  [ 0.        0.        0.       ...  0.        0.        0.      ]]\n",
            "\n",
            " [[-0.6274   -0.1984   -0.2056   ...  0.7495   -0.566     0.1765  ]\n",
            "  [ 0.04065  -0.2345    1.25     ...  0.7715   -0.1938    0.864   ]\n",
            "  [ 0.3613   -0.2483    0.4375   ... -0.1002    0.533     0.4084  ]\n",
            "  ...\n",
            "  [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
            "  [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
            "  [ 0.        0.        0.       ...  0.        0.        0.      ]]\n",
            "\n",
            " [[ 0.2646   -1.54      1.136    ...  0.6753   -1.622    -1.66    ]\n",
            "  [ 1.814    -2.166     0.746    ...  0.2832    0.7607    0.5625  ]\n",
            "  [-0.2139   -0.2216   -0.06464  ...  0.4487   -0.579    -0.3503  ]\n",
            "  ...\n",
            "  [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
            "  [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
            "  [ 0.        0.        0.       ...  0.        0.        0.      ]]]\n"
          ]
        }
      ],
      "source": [
        "# Padding sequences to the same length -> adding zeroes to the sequences shorter than embedding_dim and cutting sequences longer than embedding_dim\n",
        "# Converting to NumPy array\n",
        "embeddings_CBOW = pad_sequences(\n",
        "    list_of_embeddings_CBOW,\n",
        "    maxlen = max_sequence_length,\n",
        "    dtype = 'float16',\n",
        "    padding = 'post',\n",
        "    truncating = 'post'\n",
        ")\n",
        "\n",
        "print(embeddings_CBOW)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "fa099ef8",
      "metadata": {
        "id": "fa099ef8",
        "outputId": "b25587f3-b16e-4195-f2ef-435a3020e3c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[-0.1522    0.2324   -0.2382   ...  0.0225    0.04294   0.05774 ]\n",
            "  [ 0.1143   -0.03464  -0.1171   ...  0.1421    0.1758   -0.3223  ]\n",
            "  [ 0.04355   0.3364    0.0258   ... -0.1736    0.1401   -0.2083  ]\n",
            "  ...\n",
            "  [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
            "  [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
            "  [ 0.        0.        0.       ...  0.        0.        0.      ]]\n",
            "\n",
            " [[-0.0746    0.4734    0.0384   ...  0.0987   -0.0737   -0.06726 ]\n",
            "  [-0.0376    0.162    -0.0973   ... -0.1958    0.2776   -0.03525 ]\n",
            "  [-0.1488    0.4314   -0.00872  ... -0.2686    0.4297   -0.1893  ]\n",
            "  ...\n",
            "  [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
            "  [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
            "  [ 0.        0.        0.       ...  0.        0.        0.      ]]\n",
            "\n",
            " [[-0.08185   0.4246   -0.03217  ... -0.09064  -0.0999    0.000683]\n",
            "  [ 0.01599  -0.09045  -0.2096   ... -0.07776  -0.01978   0.0628  ]\n",
            "  [-0.007088  0.4177   -0.3674   ... -0.2323    0.1019   -0.2091  ]\n",
            "  ...\n",
            "  [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
            "  [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
            "  [ 0.        0.        0.       ...  0.        0.        0.      ]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 0.04193   0.3157   -0.1655   ...  0.10046   0.0648   -0.318   ]\n",
            "  [-0.0908    0.4019   -0.02779  ...  0.2004    0.0496   -0.2256  ]\n",
            "  [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
            "  ...\n",
            "  [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
            "  [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
            "  [ 0.        0.        0.       ...  0.        0.        0.      ]]\n",
            "\n",
            " [[-0.0831    0.3254   -0.003763 ... -0.12225   0.1218   -0.09454 ]\n",
            "  [ 0.1332    0.6357    0.362    ...  0.03882   0.2278    0.1924  ]\n",
            "  [ 0.2217    0.0954    0.1256   ...  0.04855   0.3872    0.1147  ]\n",
            "  ...\n",
            "  [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
            "  [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
            "  [ 0.        0.        0.       ...  0.        0.        0.      ]]\n",
            "\n",
            " [[ 0.11444   0.2081   -0.1337   ... -0.07574  -0.02937  -0.3013  ]\n",
            "  [ 0.269     0.1636   -0.252    ...  0.02148   0.1167   -0.07404 ]\n",
            "  [ 0.1722   -0.1083   -0.1652   ...  0.0484    0.2532   -0.5317  ]\n",
            "  ...\n",
            "  [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
            "  [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
            "  [ 0.        0.        0.       ...  0.        0.        0.      ]]]\n"
          ]
        }
      ],
      "source": [
        "# Padding sequences to the same length -> adding zeroes to the sequences shorter than embedding_dim and cutting sequences longer than embedding_dim\n",
        "# Converting to NumPy array\n",
        "embeddings_SG = pad_sequences(\n",
        "    list_of_embeddings_SG,\n",
        "    maxlen = max_sequence_length,\n",
        "    dtype = 'float16',\n",
        "    padding = 'post',\n",
        "    truncating = 'post'\n",
        ")\n",
        "\n",
        "print(embeddings_SG)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "c4427065",
      "metadata": {
        "id": "c4427065",
        "outputId": "ea4f0e26-ce29-4656-fb60-1917dc2b39e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimensions of embeddings_CBOW: (54263, 30, 300)\n",
            "Dimensions of embeddings_SG: (54263, 30, 300)\n"
          ]
        }
      ],
      "source": [
        "# Checking the dimensions of the embeddings\n",
        "print(f\"Dimensions of embeddings_CBOW: {embeddings_CBOW.shape}\") # (number_of_examples, sequence_length, embedding_dim)\n",
        "print(f\"Dimensions of embeddings_SG: {embeddings_SG.shape}\") # (number_of_examples, sequence_length, embedding_dim)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c594108c",
      "metadata": {
        "id": "c594108c"
      },
      "source": [
        "# RNN predictions for Word2Vec embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1daf43d",
      "metadata": {
        "id": "b1daf43d"
      },
      "source": [
        "### Predictions for SG embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "352dbd46",
      "metadata": {
        "id": "352dbd46",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c242a86-7c2b-4239-ff8d-7c6718262b66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Training a model for emotion: anger ---\n",
            "  --- Fold 1/5 ---\n",
            "    Fold 1 - Loss: 0.1110, Accuracy: 0.9666, Precision: 0.5960, Recall: 0.2296, F1-Score: 0.3315, ROC AUC: 0.8645\n",
            "  --- Fold 2/5 ---\n",
            "    Fold 2 - Loss: 0.1194, Accuracy: 0.9669, Precision: 0.7538, Recall: 0.1250, F1-Score: 0.2144, ROC AUC: 0.8514\n",
            "  --- Fold 3/5 ---\n",
            "    Fold 3 - Loss: 0.1179, Accuracy: 0.9665, Precision: 0.6707, Recall: 0.1403, F1-Score: 0.2321, ROC AUC: 0.8625\n",
            "  --- Fold 4/5 ---\n",
            "    Fold 4 - Loss: 0.1145, Accuracy: 0.9682, Precision: 0.6643, Recall: 0.2423, F1-Score: 0.3551, ROC AUC: 0.8587\n",
            "  --- Fold 5/5 ---\n",
            "    Fold 5 - Loss: 0.1189, Accuracy: 0.9668, Precision: 0.6404, Recall: 0.1862, F1-Score: 0.2885, ROC AUC: 0.8437\n",
            "\n",
            "--- Training a model for emotion: joy ---\n",
            "  --- Fold 1/5 ---\n",
            "    Fold 1 - Loss: 0.0971, Accuracy: 0.9715, Precision: 0.6558, Recall: 0.2829, F1-Score: 0.3953, ROC AUC: 0.8781\n",
            "  --- Fold 2/5 ---\n",
            "    Fold 2 - Loss: 0.0965, Accuracy: 0.9721, Precision: 0.6311, Recall: 0.3641, F1-Score: 0.4618, ROC AUC: 0.8675\n",
            "  --- Fold 3/5 ---\n",
            "    Fold 3 - Loss: 0.0946, Accuracy: 0.9720, Precision: 0.6199, Recall: 0.3838, F1-Score: 0.4740, ROC AUC: 0.8957\n",
            "  --- Fold 4/5 ---\n",
            "    Fold 4 - Loss: 0.0914, Accuracy: 0.9736, Precision: 0.6411, Recall: 0.4454, F1-Score: 0.5256, ROC AUC: 0.8913\n",
            "  --- Fold 5/5 ---\n",
            "    Fold 5 - Loss: 0.0918, Accuracy: 0.9730, Precision: 0.6221, Recall: 0.4566, F1-Score: 0.5267, ROC AUC: 0.8878\n"
          ]
        }
      ],
      "source": [
        "# 5-fold cross validation using Bidirectional LSTM RNN\n",
        "# Model parameters\n",
        "n_splits = 5 # 5-fold cross-validation\n",
        "epochs = 50\n",
        "batch_size = 16\n",
        "lstm_units = 128\n",
        "dropout_rate = 0.3\n",
        "\n",
        "emotion_columns = ['anger', 'joy'] # Column names\n",
        "all_emotions_results_SG = {}\n",
        "\n",
        "for emotion_column_name in emotion_columns:\n",
        "    print(f\"\\n--- Training a model for emotion: {emotion_column_name} ---\")\n",
        "\n",
        "    y_binary = goemotions_data[emotion_column_name].values\n",
        "\n",
        "    # Initialize list to store results for individual folds of this emotion\n",
        "    emotion_fold_results = []\n",
        "\n",
        "    # StratifiedKFold initialization\n",
        "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "    # nside loop: 5-fold cross-validation\n",
        "    for fold, (train_index, val_index) in enumerate(skf.split(embeddings_SG, y_binary)):\n",
        "        print(f\"  --- Fold {fold + 1}/{n_splits} ---\")\n",
        "\n",
        "        # Splitting data to train and validation sets for the current fold\n",
        "        X_train_fold, X_val_fold = embeddings_SG[train_index], embeddings_SG[val_index]\n",
        "        y_train_fold, y_val_fold = y_binary[train_index], y_binary[val_index]\n",
        "\n",
        "        clear_session() # In each fold we train model from the beginning\n",
        "\n",
        "        # Building an LSTM Bidirectional model\n",
        "        model = Sequential()\n",
        "        model.add(Input(shape=(max_sequence_length, embedding_dim_SG)))\n",
        "        model.add(Bidirectional(LSTM(lstm_units, return_sequences=False)))\n",
        "        model.add(Dropout(dropout_rate))\n",
        "        model.add(Dense(64, activation='relu'))\n",
        "        model.add(Dropout(dropout_rate))\n",
        "        model.add(Dense(1, activation='sigmoid')) # 1 neuoron for binary classification (sigmoid activation)\n",
        "\n",
        "        # Model compilation for binary classification\n",
        "        model.compile(\n",
        "            optimizer='adam',\n",
        "            loss='binary_crossentropy',\n",
        "            metrics=['accuracy']\n",
        "        )\n",
        "\n",
        "        # Early Stopping callback\n",
        "        early_stopping_callback = EarlyStopping(\n",
        "            monitor='val_accuracy',\n",
        "            patience=5,\n",
        "            restore_best_weights=True,\n",
        "            verbose=0\n",
        "        )\n",
        "\n",
        "        # Training the model\n",
        "        history = model.fit(\n",
        "            X_train_fold, y_train_fold,\n",
        "            epochs=epochs,\n",
        "            batch_size=batch_size,\n",
        "            validation_data=(X_val_fold, y_val_fold),\n",
        "            callbacks=[early_stopping_callback],\n",
        "            verbose=0\n",
        "        )\n",
        "\n",
        "        # Evaluating the model\n",
        "        loss, accuracy = model.evaluate(X_val_fold, y_val_fold, verbose=0)\n",
        "\n",
        "        # Getting predictions\n",
        "        y_pred_proba = model.predict(X_val_fold, verbose=0)\n",
        "        y_pred = (y_pred_proba > 0.5).astype(int) # Binary prediction (0 ili 1)\n",
        "\n",
        "        # Calculating metrics\n",
        "        precision = precision_score(y_val_fold, y_pred, zero_division=0)\n",
        "        recall = recall_score(y_val_fold, y_pred, zero_division=0)\n",
        "        f1 = f1_score(y_val_fold, y_pred, zero_division=0)\n",
        "\n",
        "        if len(np.unique(y_val_fold)) < 2: # Cannot calculate if validation set doesn't have both classes\n",
        "            roc_auc = np.nan\n",
        "        else:\n",
        "            roc_auc = roc_auc_score(y_val_fold, y_pred_proba)\n",
        "\n",
        "        print(f\"    Fold {fold + 1} - Loss: {loss:.4f}, Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1-Score: {f1:.4f}, ROC AUC: {roc_auc:.4f}\")\n",
        "\n",
        "        # Store results for the current fold\n",
        "        emotion_fold_results.append({\n",
        "            'fold': fold + 1,\n",
        "            'loss': loss,\n",
        "            'accuracy': accuracy,\n",
        "            'precision': precision,\n",
        "            'recall': recall,\n",
        "            'f1_score': f1,\n",
        "            'roc_auc': roc_auc\n",
        "        })\n",
        "\n",
        "    # Store all fold results for the current emotion\n",
        "    all_emotions_results_SG[emotion_column_name] = emotion_fold_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "d221c1c5",
      "metadata": {
        "id": "d221c1c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc2f5d30-e182-4c5f-bafa-3a557857f919"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Results for emotion: anger\n",
            "  Accuracy:  0.9670 +/- 0.0006\n",
            "  Precision: 0.6651 +/- 0.0516\n",
            "  Recall:    0.1847 +/- 0.0466\n",
            "  F1-Score:  0.2843 +/- 0.0545\n",
            "  ROC AUC:   0.8562 +/- 0.0077\n",
            "------------------------------\n",
            "\n",
            "Results for emotion: joy\n",
            "  Accuracy:  0.9724 +/- 0.0007\n",
            "  Precision: 0.6340 +/- 0.0132\n",
            "  Recall:    0.3866 +/- 0.0626\n",
            "  F1-Score:  0.4767 +/- 0.0485\n",
            "  ROC AUC:   0.8841 +/- 0.0101\n",
            "------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Calculating and printing the average results for each emotion across all folds\n",
        "for emotion, fold_results_list in all_emotions_results_SG.items():\n",
        "    print(f\"\\nResults for emotion: {emotion}\")\n",
        "\n",
        "    accuracies = []\n",
        "    precisions = []\n",
        "    recalls = []\n",
        "    f1_scores = []\n",
        "    roc_aucs = []\n",
        "\n",
        "    for result_dict in fold_results_list:\n",
        "        accuracies.append(result_dict['accuracy'])\n",
        "        precisions.append(result_dict['precision'])\n",
        "        recalls.append(result_dict['recall'])\n",
        "        f1_scores.append(result_dict['f1_score'])\n",
        "        roc_aucs.append(result_dict['roc_auc'])\n",
        "\n",
        "    # Calculate mean and standard deviation for each metric\n",
        "    avg_accuracy = np.mean(accuracies)\n",
        "    std_accuracy = np.std(accuracies)\n",
        "\n",
        "    avg_precision = np.mean(precisions)\n",
        "    std_precision = np.std(precisions)\n",
        "\n",
        "    avg_recall = np.mean(recalls)\n",
        "    std_recall = np.std(recalls)\n",
        "\n",
        "    avg_f1_score = np.mean(f1_scores)\n",
        "    std_f1_score = np.std(f1_scores)\n",
        "\n",
        "    avg_roc_auc = np.nanmean(roc_aucs)\n",
        "    std_roc_auc = np.nanstd(roc_aucs)\n",
        "\n",
        "    print(f\"  Accuracy:  {avg_accuracy:.4f} +/- {std_accuracy:.4f}\")\n",
        "    print(f\"  Precision: {avg_precision:.4f} +/- {std_precision:.4f}\")\n",
        "    print(f\"  Recall:    {avg_recall:.4f} +/- {std_recall:.4f}\")\n",
        "    print(f\"  F1-Score:  {avg_f1_score:.4f} +/- {std_f1_score:.4f}\")\n",
        "\n",
        "    if not np.isnan(avg_roc_auc):\n",
        "        print(f\"  ROC AUC:   {avg_roc_auc:.4f} +/- {std_roc_auc:.4f}\")\n",
        "    else:\n",
        "        print(\"  ROC AUC:   N/A (not enough classes in validation folds)\")\n",
        "\n",
        "    print(\"-\" * 30)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9411973",
      "metadata": {
        "id": "b9411973"
      },
      "source": [
        "### Predictions for CBOW embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "777b8f2f",
      "metadata": {
        "id": "777b8f2f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "345223f3-369e-4d32-a93a-2774841bd4c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Training a model for emotion: anger ---\n",
            "  --- Fold 1/5 ---\n",
            "    Fold 1 - Loss: 0.1162, Accuracy: 0.9667, Precision: 0.6962, Recall: 0.1403, F1-Score: 0.2335, ROC AUC: 0.8531\n",
            "  --- Fold 2/5 ---\n",
            "    Fold 2 - Loss: 0.1200, Accuracy: 0.9665, Precision: 0.6129, Recall: 0.1939, F1-Score: 0.2946, ROC AUC: 0.8414\n",
            "  --- Fold 3/5 ---\n",
            "    Fold 3 - Loss: 0.1179, Accuracy: 0.9664, Precision: 0.6337, Recall: 0.1633, F1-Score: 0.2596, ROC AUC: 0.8414\n",
            "  --- Fold 4/5 ---\n",
            "    Fold 4 - Loss: 0.1183, Accuracy: 0.9684, Precision: 0.7094, Recall: 0.2117, F1-Score: 0.3261, ROC AUC: 0.8451\n",
            "  --- Fold 5/5 ---\n",
            "    Fold 5 - Loss: 0.1630, Accuracy: 0.9662, Precision: 0.5850, Recall: 0.2194, F1-Score: 0.3191, ROC AUC: 0.7982\n",
            "\n",
            "--- Training a model for emotion: joy ---\n",
            "  --- Fold 1/5 ---\n",
            "    Fold 1 - Loss: 0.1007, Accuracy: 0.9704, Precision: 0.6184, Recall: 0.2633, F1-Score: 0.3694, ROC AUC: 0.8533\n",
            "  --- Fold 2/5 ---\n",
            "    Fold 2 - Loss: 0.0988, Accuracy: 0.9713, Precision: 0.6009, Recall: 0.3754, F1-Score: 0.4621, ROC AUC: 0.8543\n",
            "  --- Fold 3/5 ---\n",
            "    Fold 3 - Loss: 0.0960, Accuracy: 0.9722, Precision: 0.6151, Recall: 0.4118, F1-Score: 0.4933, ROC AUC: 0.8769\n",
            "  --- Fold 4/5 ---\n",
            "    Fold 4 - Loss: 0.1048, Accuracy: 0.9716, Precision: 0.6522, Recall: 0.2941, F1-Score: 0.4054, ROC AUC: 0.8608\n",
            "  --- Fold 5/5 ---\n",
            "    Fold 5 - Loss: 0.0963, Accuracy: 0.9727, Precision: 0.6649, Recall: 0.3445, F1-Score: 0.4539, ROC AUC: 0.8710\n"
          ]
        }
      ],
      "source": [
        "# 5-fold cross validation using Bidirectional LSTM RNN\n",
        "# Model parameters\n",
        "n_splits = 5 # 5-fold cross-validation\n",
        "epochs = 50\n",
        "batch_size = 16\n",
        "lstm_units = 128\n",
        "dropout_rate = 0.3\n",
        "\n",
        "emotion_columns = ['anger', 'joy'] # column names\n",
        "all_emotions_results_CBOW = {}\n",
        "\n",
        "for emotion_column_name in emotion_columns:\n",
        "    print(f\"\\n--- Training a model for emotion: {emotion_column_name} ---\")\n",
        "\n",
        "    y_binary = goemotions_data[emotion_column_name].values\n",
        "\n",
        "    # Initialize list to store results for individual folds of this emotion\n",
        "    emotion_fold_results = []\n",
        "\n",
        "    # StratifiedKFold initialization\n",
        "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "    # nside loop: 5-fold cross-validation\n",
        "    for fold, (train_index, val_index) in enumerate(skf.split(embeddings_CBOW, y_binary)):\n",
        "        print(f\"  --- Fold {fold + 1}/{n_splits} ---\")\n",
        "\n",
        "        # Splitting data to train and validation sets for the current fold\n",
        "        X_train_fold, X_val_fold = embeddings_CBOW[train_index], embeddings_CBOW[val_index]\n",
        "        y_train_fold, y_val_fold = y_binary[train_index], y_binary[val_index]\n",
        "\n",
        "        clear_session()  # In each fold we train model from the beginning\n",
        "\n",
        "        # Building an LSTM Bidirectional model\n",
        "        model = Sequential()\n",
        "        model.add(Input(shape=(max_sequence_length, embedding_dim_CBOW)))\n",
        "        model.add(Bidirectional(LSTM(lstm_units, return_sequences=False)))\n",
        "        model.add(Dropout(dropout_rate))\n",
        "        model.add(Dense(64, activation='relu'))\n",
        "        model.add(Dropout(dropout_rate))\n",
        "        model.add(Dense(1, activation='sigmoid')) # 1 neuoron for binary classification (sigmoid activation)\n",
        "\n",
        "        # Model compilation for binary classification\n",
        "        model.compile(\n",
        "            optimizer='adam',\n",
        "            loss='binary_crossentropy',\n",
        "            metrics=['accuracy']\n",
        "        )\n",
        "\n",
        "        # Early Stopping callback\n",
        "        early_stopping_callback = EarlyStopping(\n",
        "            monitor='val_accuracy',\n",
        "            patience=5,\n",
        "            restore_best_weights=True,\n",
        "            verbose=0\n",
        "        )\n",
        "\n",
        "        # Training the model\n",
        "        history = model.fit(\n",
        "            X_train_fold, y_train_fold,\n",
        "            epochs=epochs,\n",
        "            batch_size=batch_size,\n",
        "            validation_data=(X_val_fold, y_val_fold),\n",
        "            callbacks=[early_stopping_callback],\n",
        "            verbose=0\n",
        "        )\n",
        "\n",
        "        # Evaluating the model\n",
        "        loss, accuracy = model.evaluate(X_val_fold, y_val_fold, verbose=0)\n",
        "\n",
        "        # Getting predictions\n",
        "        y_pred_proba = model.predict(X_val_fold, verbose=0)\n",
        "        y_pred = (y_pred_proba > 0.5).astype(int) # Binary prediction (0 ili 1)\n",
        "\n",
        "        # Calculating metrics, with zero_division=0 to handle division by zero cases\n",
        "        precision = precision_score(y_val_fold, y_pred, zero_division=0)\n",
        "        recall = recall_score(y_val_fold, y_pred, zero_division=0)\n",
        "        f1 = f1_score(y_val_fold, y_pred, zero_division=0)\n",
        "\n",
        "        if len(np.unique(y_val_fold)) < 2: # Cannot calculate if validation set doesn't have both classes\n",
        "            roc_auc = np.nan\n",
        "        else:\n",
        "            roc_auc = roc_auc_score(y_val_fold, y_pred_proba) # Use probabilities for ROC AUC\n",
        "\n",
        "        print(f\"    Fold {fold + 1} - Loss: {loss:.4f}, Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1-Score: {f1:.4f}, ROC AUC: {roc_auc:.4f}\")\n",
        "\n",
        "        # Store results for the current fold\n",
        "        emotion_fold_results.append({\n",
        "            'fold': fold + 1,\n",
        "            'loss': loss,\n",
        "            'accuracy': accuracy,\n",
        "            'precision': precision,\n",
        "            'recall': recall,\n",
        "            'f1_score': f1,\n",
        "            'roc_auc': roc_auc\n",
        "        })\n",
        "\n",
        "    # Store all fold results for the current emotion\n",
        "    all_emotions_results_CBOW[emotion_column_name] = emotion_fold_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "2c099536",
      "metadata": {
        "id": "2c099536",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6ddbd74-5318-4f30-860b-f6cb1e105c53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Results for emotion: anger\n",
            "  Accuracy:  0.9668 +/- 0.0008\n",
            "  Precision: 0.6474 +/- 0.0479\n",
            "  Recall:    0.1857 +/- 0.0298\n",
            "  F1-Score:  0.2866 +/- 0.0353\n",
            "  ROC AUC:   0.8358 +/- 0.0193\n",
            "------------------------------\n",
            "\n",
            "Results for emotion: joy\n",
            "  Accuracy:  0.9716 +/- 0.0008\n",
            "  Precision: 0.6303 +/- 0.0241\n",
            "  Recall:    0.3378 +/- 0.0536\n",
            "  F1-Score:  0.4368 +/- 0.0439\n",
            "  ROC AUC:   0.8632 +/- 0.0093\n",
            "------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Calculating and printing the average results for each emotion across all folds\n",
        "for emotion, fold_results_list in all_emotions_results_CBOW.items():\n",
        "    print(f\"\\nResults for emotion: {emotion}\")\n",
        "\n",
        "    accuracies = []\n",
        "    precisions = []\n",
        "    recalls = []\n",
        "    f1_scores = []\n",
        "    roc_aucs = []\n",
        "\n",
        "    for result_dict in fold_results_list:\n",
        "        accuracies.append(result_dict['accuracy'])\n",
        "        precisions.append(result_dict['precision'])\n",
        "        recalls.append(result_dict['recall'])\n",
        "        f1_scores.append(result_dict['f1_score'])\n",
        "        roc_aucs.append(result_dict['roc_auc'])\n",
        "\n",
        "    # Calculate mean and standard deviation for each metric\n",
        "    avg_accuracy = np.mean(accuracies)\n",
        "    std_accuracy = np.std(accuracies)\n",
        "\n",
        "    avg_precision = np.mean(precisions)\n",
        "    std_precision = np.std(precisions)\n",
        "\n",
        "    avg_recall = np.mean(recalls)\n",
        "    std_recall = np.std(recalls)\n",
        "\n",
        "    avg_f1_score = np.mean(f1_scores)\n",
        "    std_f1_score = np.std(f1_scores)\n",
        "\n",
        "    avg_roc_auc = np.nanmean(roc_aucs)\n",
        "    std_roc_auc = np.nanstd(roc_aucs)\n",
        "\n",
        "    print(f\"  Accuracy:  {avg_accuracy:.4f} +/- {std_accuracy:.4f}\")\n",
        "    print(f\"  Precision: {avg_precision:.4f} +/- {std_precision:.4f}\")\n",
        "    print(f\"  Recall:    {avg_recall:.4f} +/- {std_recall:.4f}\")\n",
        "    print(f\"  F1-Score:  {avg_f1_score:.4f} +/- {std_f1_score:.4f}\")\n",
        "\n",
        "    if not np.isnan(avg_roc_auc):\n",
        "        print(f\"  ROC AUC:   {avg_roc_auc:.4f} +/- {std_roc_auc:.4f}\")\n",
        "    else:\n",
        "        print(\"  ROC AUC:   N/A (not enough classes in validation folds)\")\n",
        "\n",
        "    print(\"-\" * 30)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c409131",
      "metadata": {
        "id": "9c409131"
      },
      "source": [
        "# BERT embeddings"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Connecting with google drive where fine tuned models are stored\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9mrkTSiKhuM",
        "outputId": "edd3c673-b832-489d-cfa6-efa5d093361d"
      },
      "id": "Y9mrkTSiKhuM",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "f8db8c31",
      "metadata": {
        "id": "f8db8c31"
      },
      "outputs": [],
      "source": [
        "# Import of fine tuned bert model\n",
        "model_path = \"/content/drive/My Drive/fine_tuned_bert\"\n",
        "bert_tokenizer = BertTokenizer.from_pretrained(model_path)\n",
        "bert_model = BertForMaskedLM.from_pretrained(model_path)\n",
        "embedding_dim_bert = bert_model.config.hidden_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "45a0fe69",
      "metadata": {
        "id": "45a0fe69"
      },
      "outputs": [],
      "source": [
        "# Function for getting bert embeddings\n",
        "def get_bert_embeddings(sentence, bert_model, bert_tokenizer, max_sequence_length_for_lstm):\n",
        "\n",
        "    padding_zeroes = np.zeros(embedding_dim_bert, dtype=np.float16) # used to pad sequences shorter than sequence_length (50)\n",
        "\n",
        "    inputs = bert_tokenizer(\n",
        "        sentence,\n",
        "        return_tensors='pt',\n",
        "        truncation=True\n",
        "    )\n",
        "\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    bert_model.to(device)\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = bert_model(\n",
        "            input_ids=inputs['input_ids'],\n",
        "            attention_mask=inputs.get('attention_mask', None),\n",
        "            token_type_ids=inputs.get('token_type_ids', None),\n",
        "            output_hidden_states=True\n",
        "        )\n",
        "\n",
        "    # Get the last hidden state (token embeddings)\n",
        "    token_embeddings_np = outputs.hidden_states[-1].squeeze(0).to(torch.float16).cpu().numpy()\n",
        "    #token_embeddings_np = outputs.hidden_states[-1].squeeze(0).cpu().numpy()\n",
        "    input_ids = inputs['input_ids'].squeeze(0).cpu().numpy()\n",
        "\n",
        "    # Filter out special tokens and empty strings\n",
        "    filtered_embeddings_list = []\n",
        "    for i, token_id in enumerate(input_ids):\n",
        "        token_str = bert_tokenizer.decode(token_id)\n",
        "\n",
        "        if token_str in bert_tokenizer.all_special_tokens or not token_str.strip():\n",
        "            continue\n",
        "\n",
        "        filtered_embeddings_list.append(token_embeddings_np[i])\n",
        "\n",
        "    current_len = len(filtered_embeddings_list)\n",
        "\n",
        "    if current_len == 0:\n",
        "        return np.full((max_sequence_length_for_lstm, embedding_dim_bert), padding_zeroes, dtype=np.float16)\n",
        "\n",
        "    # Initialize the final embeddings array with padding zeroes\n",
        "    final_embeddings_array = np.full((max_sequence_length_for_lstm, embedding_dim_bert), padding_zeroes, dtype=np.float16)\n",
        "\n",
        "    # If the current length is greater than or equal to the max sequence length (50), truncate the list\n",
        "    # else, fill the array with the available embeddings\n",
        "    if current_len >= max_sequence_length_for_lstm:\n",
        "        final_embeddings_array = np.array(filtered_embeddings_list[:max_sequence_length_for_lstm], dtype=np.float16)\n",
        "    else:\n",
        "        final_embeddings_array[:current_len] = np.array(filtered_embeddings_list, dtype=np.float16)\n",
        "\n",
        "    return final_embeddings_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "08219673",
      "metadata": {
        "id": "08219673"
      },
      "outputs": [],
      "source": [
        "# Getting bert embeddings for each word in the sentence\n",
        "list_of_embeddings_BERT = [\n",
        "   get_bert_embeddings(text, bert_model, bert_tokenizer, max_sequence_length)\n",
        "    for text in goemotions_data['text']\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "69c2cb75",
      "metadata": {
        "id": "69c2cb75",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "169a9009-d292-47c3-c41a-23f498bd8a15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[-0.536    -0.2008    0.8955   ...  0.2314   -0.2686    0.7583  ]\n",
            "  [-0.04874   0.363     1.516    ...  0.048    -0.6094   -0.01744 ]\n",
            "  [-0.1783   -0.1528   -0.235    ...  0.27     -0.03848  -0.336   ]\n",
            "  ...\n",
            "  [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
            "  [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
            "  [ 0.        0.        0.       ...  0.        0.        0.      ]]\n",
            "\n",
            " [[-0.02016  -0.002483  1.163    ... -0.2085   -0.10297   0.1288  ]\n",
            "  [ 0.2874    0.006336  0.2288   ... -0.943    -0.2607    0.4963  ]\n",
            "  [-0.6045   -0.5537    0.437    ... -0.2007    0.509    -0.648   ]\n",
            "  ...\n",
            "  [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
            "  [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
            "  [ 0.        0.        0.       ...  0.        0.        0.      ]]\n",
            "\n",
            " [[ 0.348     0.1493    0.07184  ... -0.1663   -0.1428    0.4436  ]\n",
            "  [-0.576    -0.363     0.461    ...  0.2825    0.589    -0.4058  ]\n",
            "  [ 0.7134    0.782     1.447    ... -0.3298   -0.1384   -1.09    ]\n",
            "  ...\n",
            "  [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
            "  [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
            "  [ 0.        0.        0.       ...  0.        0.        0.      ]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.2446   -0.01314   0.511    ... -0.3997   -0.4905    0.9204  ]\n",
            "  [-0.4011    0.3577    0.4019   ... -0.4387    0.3406    0.1594  ]\n",
            "  [-0.2479   -0.199    -0.05322  ... -0.2622    0.0969    0.2256  ]\n",
            "  ...\n",
            "  [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
            "  [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
            "  [ 0.        0.        0.       ...  0.        0.        0.      ]]\n",
            "\n",
            " [[ 0.2659    0.0684    0.912    ... -0.1698   -0.1954    1.309   ]\n",
            "  [ 0.0612   -0.1048    1.009    ... -0.07623  -0.619     0.4016  ]\n",
            "  [ 0.2256   -0.3862    1.427    ... -0.02853   0.5845    0.426   ]\n",
            "  ...\n",
            "  [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
            "  [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
            "  [ 0.        0.        0.       ...  0.        0.        0.      ]]\n",
            "\n",
            " [[ 0.12085  -0.3723    0.5005   ...  0.08014  -0.1594    0.605   ]\n",
            "  [-0.3716   -0.5615    0.1748   ...  0.01665   0.5205    0.5684  ]\n",
            "  [-0.482     0.1437    0.6377   ...  0.3464    0.3875   -0.1963  ]\n",
            "  ...\n",
            "  [-0.4424    0.1857    0.7256   ...  0.01184  -0.16      0.1534  ]\n",
            "  [-0.8335    0.2607    0.2291   ... -0.0341    0.2932   -0.298   ]\n",
            "  [-0.2441    0.4407    0.3994   ... -0.0729    0.2551    0.242   ]]]\n"
          ]
        }
      ],
      "source": [
        "# Padding sequences to the same length -> adding zeroes to the sequences shorter than embedding_dim and cutting sequences longer than embedding_dim\n",
        "# Converting to NumPy array\n",
        "embeddings_BERT = pad_sequences(\n",
        "    list_of_embeddings_BERT,\n",
        "    maxlen = max_sequence_length,\n",
        "    dtype = 'float16',\n",
        "    padding = 'post',\n",
        "    truncating = 'post'\n",
        ")\n",
        "\n",
        "print (embeddings_BERT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "8f5b5dc3",
      "metadata": {
        "id": "8f5b5dc3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f3b2bb3-1608-4fdd-c113-65ba128fb9a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dimensions of embeddings_BERT: (54263, 30, 768)\n"
          ]
        }
      ],
      "source": [
        "# Checking the dimensions of the embeddings\n",
        "print(f\"\\nDimensions of embeddings_BERT: {embeddings_BERT.shape}\") # (number_of_examples, sequence_length, embedding_dim)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "855f1d9c",
      "metadata": {
        "id": "855f1d9c"
      },
      "source": [
        "# RNN predictions for BERT Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "b492d6e2",
      "metadata": {
        "id": "b492d6e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fffcd2b1-01ec-4c5d-dd7a-deb7d0e09bc1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Configuring Keras Mixed Precision Policy...\n",
            "  GPU detected. Setting policy to 'mixed_float16' for optimal performance and memory.\n",
            "  Global Keras policy set to: mixed_float16\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from keras import mixed_precision\n",
        "print(\"Configuring Keras Mixed Precision Policy...\")\n",
        "try:\n",
        "    if tf.config.list_physical_devices('GPU'):\n",
        "        # On GPU, 'mixed_float16' is recommended as it's typically faster and saves memory\n",
        "        # while maintaining numerical stability by keeping some variables in float32.\n",
        "        policy = mixed_precision.Policy('mixed_float16')\n",
        "        print(\"  GPU detected. Setting policy to 'mixed_float16' for optimal performance and memory.\")\n",
        "    else:\n",
        "        policy = mixed_precision.Policy('float16')\n",
        "        print(\"  CPU detected. Setting policy to 'float16' for maximum memory optimization.\")\n",
        "\n",
        "    mixed_precision.set_global_policy(policy)\n",
        "    print(f\"  Global Keras policy set to: {mixed_precision.global_policy().name}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"  Could not set mixed precision policy: {e}\")\n",
        "    print(\"  Proceeding with default (likely float32) policy as a fallback.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "07f5d6ab",
      "metadata": {
        "id": "07f5d6ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "914c9813-0a29-45cb-d15a-24c52433fa03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Training a model for emotion: anger ---\n",
            "  --- Fold 1/5 ---\n",
            "    Fold 1 - Loss: 0.1025, Accuracy: 0.9658, Precision: 0.5436, Recall: 0.3342, F1-Score: 0.4139, ROC AUC: 0.9222\n",
            "  --- Fold 2/5 ---\n",
            "    Fold 2 - Loss: 0.1022, Accuracy: 0.9681, Precision: 0.6533, Recall: 0.2500, F1-Score: 0.3616, ROC AUC: 0.9101\n",
            "  --- Fold 3/5 ---\n",
            "    Fold 3 - Loss: 0.1005, Accuracy: 0.9674, Precision: 0.6338, Recall: 0.2296, F1-Score: 0.3371, ROC AUC: 0.9192\n",
            "  --- Fold 4/5 ---\n",
            "    Fold 4 - Loss: 0.0987, Accuracy: 0.9692, Precision: 0.7589, Recall: 0.2168, F1-Score: 0.3373, ROC AUC: 0.9221\n",
            "  --- Fold 5/5 ---\n",
            "    Fold 5 - Loss: 0.1090, Accuracy: 0.9667, Precision: 0.5987, Recall: 0.2398, F1-Score: 0.3424, ROC AUC: 0.9088\n",
            "\n",
            "--- Training a model for emotion: joy ---\n",
            "  --- Fold 1/5 ---\n",
            "    Fold 1 - Loss: 0.0867, Accuracy: 0.9724, Precision: 0.6748, Recall: 0.3081, F1-Score: 0.4231, ROC AUC: 0.9219\n",
            "  --- Fold 2/5 ---\n",
            "    Fold 2 - Loss: 0.0905, Accuracy: 0.9722, Precision: 0.6455, Recall: 0.3417, F1-Score: 0.4469, ROC AUC: 0.9188\n",
            "  --- Fold 3/5 ---\n",
            "    Fold 3 - Loss: 0.0843, Accuracy: 0.9731, Precision: 0.6526, Recall: 0.3894, F1-Score: 0.4877, ROC AUC: 0.9265\n",
            "  --- Fold 4/5 ---\n",
            "    Fold 4 - Loss: 0.0870, Accuracy: 0.9724, Precision: 0.6647, Recall: 0.3221, F1-Score: 0.4340, ROC AUC: 0.9246\n",
            "  --- Fold 5/5 ---\n",
            "    Fold 5 - Loss: 0.0827, Accuracy: 0.9731, Precision: 0.6360, Recall: 0.4258, F1-Score: 0.5101, ROC AUC: 0.9310\n"
          ]
        }
      ],
      "source": [
        "# 5-fold cross validation using Bidirectional LSTM RNN\n",
        "# Model parameters\n",
        "n_splits = 5 # 5-fold cross-validation\n",
        "epochs = 50\n",
        "batch_size = 16\n",
        "lstm_units = 128\n",
        "dropout_rate = 0.3\n",
        "\n",
        "emotion_columns = ['anger', 'joy'] # column names\n",
        "all_emotions_results_BERT = {}\n",
        "\n",
        "for emotion_column_name in emotion_columns:\n",
        "    print(f\"\\n--- Training a model for emotion: {emotion_column_name} ---\")\n",
        "\n",
        "    y_binary = goemotions_data[emotion_column_name].values\n",
        "\n",
        "    # Initialize list to store results for individual folds of this emotion\n",
        "    emotion_fold_results = []\n",
        "\n",
        "    # StratifiedKFold initialization\n",
        "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "    # nside loop: 5-fold cross-validation\n",
        "    for fold, (train_index, val_index) in enumerate(skf.split(embeddings_BERT, y_binary)):\n",
        "        print(f\"  --- Fold {fold + 1}/{n_splits} ---\")\n",
        "\n",
        "        # Splitting data to train and validation sets for the current fold\n",
        "        X_train_fold, X_val_fold = embeddings_BERT[train_index], embeddings_BERT[val_index]\n",
        "        y_train_fold, y_val_fold = y_binary[train_index], y_binary[val_index]\n",
        "\n",
        "        clear_session()  # In each fold we train model from the beginning\n",
        "\n",
        "        # Building an LSTM Bidirectional model\n",
        "        model = Sequential()\n",
        "        model.add(Input(shape=(max_sequence_length, embedding_dim_bert)))\n",
        "        model.add(Bidirectional(LSTM(lstm_units, return_sequences=False)))\n",
        "        model.add(Dropout(dropout_rate))\n",
        "        model.add(Dense(64, activation='relu'))\n",
        "        model.add(Dropout(dropout_rate))\n",
        "        model.add(Dense(1, activation='sigmoid')) # 1 neuoron for binary classification (sigmoid activation)\n",
        "\n",
        "        # Model compilation for binary classification\n",
        "        model.compile(\n",
        "            optimizer='adam',\n",
        "            loss='binary_crossentropy',\n",
        "            metrics=['accuracy']\n",
        "        )\n",
        "\n",
        "        # Early Stopping callback\n",
        "        early_stopping_callback = EarlyStopping(\n",
        "            monitor='val_accuracy',\n",
        "            patience=5,\n",
        "            restore_best_weights=True,\n",
        "            verbose=0\n",
        "        )\n",
        "\n",
        "        # Training the model\n",
        "        history = model.fit(\n",
        "            X_train_fold, y_train_fold,\n",
        "            epochs=epochs,\n",
        "            batch_size=batch_size,\n",
        "            validation_data=(X_val_fold, y_val_fold),\n",
        "            callbacks=[early_stopping_callback],\n",
        "            verbose=0\n",
        "        )\n",
        "\n",
        "        # Evaluating the model\n",
        "        loss, accuracy = model.evaluate(X_val_fold, y_val_fold, verbose=0)\n",
        "\n",
        "        # Getting predictions\n",
        "        y_pred_proba = model.predict(X_val_fold, verbose=0)\n",
        "        y_pred = (y_pred_proba > 0.5).astype(int) # Binary prediction (0 ili 1)\n",
        "\n",
        "        # Calculating metrics, with zero_division=0 to handle division by zero cases\n",
        "        precision = precision_score(y_val_fold, y_pred, zero_division=0)\n",
        "        recall = recall_score(y_val_fold, y_pred, zero_division=0)\n",
        "        f1 = f1_score(y_val_fold, y_pred, zero_division=0)\n",
        "\n",
        "        if len(np.unique(y_val_fold)) < 2: # Cannot calculate if validation set doesn't have both classes\n",
        "            roc_auc = np.nan\n",
        "        else:\n",
        "            roc_auc = roc_auc_score(y_val_fold, y_pred_proba)\n",
        "\n",
        "        print(f\"    Fold {fold + 1} - Loss: {loss:.4f}, Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1-Score: {f1:.4f}, ROC AUC: {roc_auc:.4f}\")\n",
        "\n",
        "        # Store results for the current fold\n",
        "        emotion_fold_results.append({\n",
        "            'fold': fold + 1,\n",
        "            'loss': loss,\n",
        "            'accuracy': accuracy,\n",
        "            'precision': precision,\n",
        "            'recall': recall,\n",
        "            'f1_score': f1,\n",
        "            'roc_auc': roc_auc\n",
        "        })\n",
        "\n",
        "    # Store all fold results for the current emotion\n",
        "    all_emotions_results_BERT[emotion_column_name] = emotion_fold_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "6cd8e100",
      "metadata": {
        "id": "6cd8e100",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffd29752-45a2-42be-dffc-13f37608552a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Results for emotion: anger\n",
            "  Accuracy:  0.9675 +/- 0.0012\n",
            "  Precision: 0.6377 +/- 0.0712\n",
            "  Recall:    0.2541 +/- 0.0415\n",
            "  F1-Score:  0.3585 +/- 0.0291\n",
            "  ROC AUC:   0.9165 +/- 0.0059\n",
            "------------------------------\n",
            "\n",
            "Results for emotion: joy\n",
            "  Accuracy:  0.9726 +/- 0.0004\n",
            "  Precision: 0.6547 +/- 0.0138\n",
            "  Recall:    0.3574 +/- 0.0438\n",
            "  F1-Score:  0.4603 +/- 0.0331\n",
            "  ROC AUC:   0.9246 +/- 0.0041\n",
            "------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Calculating and printing the average results for each emotion across all folds\n",
        "for emotion, fold_results_list in all_emotions_results_BERT.items():\n",
        "    print(f\"\\nResults for emotion: {emotion}\")\n",
        "\n",
        "    accuracies = []\n",
        "    precisions = []\n",
        "    recalls = []\n",
        "    f1_scores = []\n",
        "    roc_aucs = []\n",
        "\n",
        "    for result_dict in fold_results_list:\n",
        "        accuracies.append(result_dict['accuracy'])\n",
        "        precisions.append(result_dict['precision'])\n",
        "        recalls.append(result_dict['recall'])\n",
        "        f1_scores.append(result_dict['f1_score'])\n",
        "        roc_aucs.append(result_dict['roc_auc'])\n",
        "\n",
        "    # Calculate mean and standard deviation for each metric\n",
        "    avg_accuracy = np.mean(accuracies)\n",
        "    std_accuracy = np.std(accuracies)\n",
        "\n",
        "    avg_precision = np.mean(precisions)\n",
        "    std_precision = np.std(precisions)\n",
        "\n",
        "    avg_recall = np.mean(recalls)\n",
        "    std_recall = np.std(recalls)\n",
        "\n",
        "    avg_f1_score = np.mean(f1_scores)\n",
        "    std_f1_score = np.std(f1_scores)\n",
        "\n",
        "    avg_roc_auc = np.nanmean(roc_aucs)\n",
        "    std_roc_auc = np.nanstd(roc_aucs)\n",
        "\n",
        "    print(f\"  Accuracy:  {avg_accuracy:.4f} +/- {std_accuracy:.4f}\")\n",
        "    print(f\"  Precision: {avg_precision:.4f} +/- {std_precision:.4f}\")\n",
        "    print(f\"  Recall:    {avg_recall:.4f} +/- {std_recall:.4f}\")\n",
        "    print(f\"  F1-Score:  {avg_f1_score:.4f} +/- {std_f1_score:.4f}\")\n",
        "\n",
        "    if not np.isnan(avg_roc_auc):\n",
        "        print(f\"  ROC AUC:   {avg_roc_auc:.4f} +/- {std_roc_auc:.4f}\")\n",
        "    else:\n",
        "        print(\"  ROC AUC:   N/A (not enough classes in validation folds)\")\n",
        "\n",
        "    print(\"-\" * 30)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}