{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3008abd3",
      "metadata": {
        "id": "3008abd3"
      },
      "source": [
        "**Nina Dobša, zadnje mijenjano 28.7.2025.**\n",
        "\n",
        "> Dodaj oznaku dugog citata\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09e15e66",
      "metadata": {
        "id": "09e15e66"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6yV_qZlJRbx",
        "outputId": "a3850a26-3dce-4736-f00e-2649e562c3f4"
      },
      "id": "J6yV_qZlJRbx",
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting gensim\n",
            "  Downloading gensim-4.3.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
            "Collecting numpy<2.0,>=1.18.5 (from gensim)\n",
            "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy<1.14.0,>=1.7.0 (from gensim)\n",
            "  Downloading scipy-1.13.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.3.0.post1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open>=1.8.1->gensim) (1.17.3)\n",
            "Downloading gensim-4.3.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.6/26.6 MB\u001b[0m \u001b[31m83.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m79.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.13.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.2/38.2 MB\u001b[0m \u001b[31m61.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy, scipy, gensim\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.16.1\n",
            "    Uninstalling scipy-1.16.1:\n",
            "      Successfully uninstalled scipy-1.16.1\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7fa1ad7b",
      "metadata": {
        "id": "7fa1ad7b"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional, Input\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.backend import clear_session\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from gensim.models import Word2Vec\n",
        "from transformers import BertTokenizer, BertForMaskedLM, BertForSequenceClassification\n",
        "import torch\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Connecting with google drive where fine tuned models are stored\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKXMzjRALI-C",
        "outputId": "ea23a0e2-af7c-49cd-af37-6fd56f4e7073"
      },
      "id": "HKXMzjRALI-C",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1f1fc99",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1f1fc99",
        "outputId": "63bcd29c-256a-4ea4-803f-1e15b662a399"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7505, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "# Uploading ISEAR data\n",
        "file_path = \"/content/drive/My Drive/data/isear_3.txt\"\n",
        "ISEAR_data = pd.read_csv(file_path, delimiter=\"|\", header=0, on_bad_lines=\"skip\", engine=\"python\")\n",
        "\n",
        "# Select only Emotion and Text columns from original dataset\n",
        "ISEAR_data = ISEAR_data[['SIT', 'Field1']]\n",
        "ISEAR_data.columns = ['text', 'emotion']\n",
        "ISEAR_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa15e2c1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aa15e2c1",
        "outputId": "a40759bf-30ed-460b-fe9c-ad238de0ff7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'anger': 0, 'disgust': 1, 'fear': 2, 'guilt': 3, 'joy': 4, 'sadness': 5, 'shame': 6}\n"
          ]
        }
      ],
      "source": [
        "# Encoding emotions (from words to numbers)\n",
        "label_encoder = LabelEncoder()\n",
        "ISEAR_data['emotion_label'] = label_encoder.fit_transform(ISEAR_data['emotion'])\n",
        "print(dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3eabb55f",
      "metadata": {
        "id": "3eabb55f"
      },
      "outputs": [],
      "source": [
        "# Defining number of classes and length of the sequence (if the sentence is shorter padding will be added)\n",
        "num_classes = 7\n",
        "max_sequence_length = 30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc2a375d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "bc2a375d",
        "outputId": "2281873c-d26c-441d-d6f3-c876466f48a1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Visualization of class distribution\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.countplot(x='emotion_label', data=ISEAR_data)\n",
        "plt.title('Distribucija klasa u ISEAR skupu podataka')\n",
        "plt.xlabel('Klasa')\n",
        "plt.ylabel('Broj uzoraka')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a1785f5",
      "metadata": {
        "id": "9a1785f5"
      },
      "source": [
        "Classes are balanced..."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09f5c618",
      "metadata": {
        "id": "09f5c618"
      },
      "source": [
        "# Word2Vec Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c9d0b62",
      "metadata": {
        "id": "5c9d0b62"
      },
      "outputs": [],
      "source": [
        "# Import of fine tuned word2vec model\n",
        "model_path_SG = \"/content/drive/My Drive/modeli/SG_15/SG_15.model\"\n",
        "model_path_CBOW = \"/content/drive/My Drive/modeli/CBOW_10/CBOW_10.model\"\n",
        "word2vec_model_SG = Word2Vec.load(model_path_SG)\n",
        "word2vec_model_CBOW = Word2Vec.load(model_path_CBOW)\n",
        "\n",
        "embedding_dim_SG = word2vec_model_SG.vector_size\n",
        "embedding_dim_CBOW = word2vec_model_CBOW.vector_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64a86909",
      "metadata": {
        "id": "64a86909"
      },
      "outputs": [],
      "source": [
        "# Function for getting word2vec embeddings\n",
        "def get_word2vec_embeddings(sentence, model):\n",
        "    # Tokenization\n",
        "    sentence = sentence.lower()\n",
        "    words = sentence.split()\n",
        "    word_embeddings = [model.wv[word] for word in words if word in model.wv]\n",
        "\n",
        "    if not word_embeddings:  # If no words are in the vocabulary, return a zero vector\n",
        "        return []\n",
        "\n",
        "    return word_embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8467d1af",
      "metadata": {
        "id": "8467d1af"
      },
      "outputs": [],
      "source": [
        "# Getting word2vec embeddings for each word in the sentence\n",
        "list_of_embeddings_CBOW = [\n",
        "   get_word2vec_embeddings(text, word2vec_model_CBOW)\n",
        "    for text in ISEAR_data['text']\n",
        "]\n",
        "\n",
        "list_of_embeddings_SG = [\n",
        "   get_word2vec_embeddings(text, word2vec_model_SG)\n",
        "    for text in ISEAR_data['text']\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41ffb79a",
      "metadata": {
        "id": "41ffb79a"
      },
      "outputs": [],
      "source": [
        "# Padding sequences to the same length -> adding zeroes to the sequences shorter than embedding_dim and cutting sequences longer than embedding_dim\n",
        "# Converting to NumPy array\n",
        "embeddings_CBOW = pad_sequences(\n",
        "    list_of_embeddings_CBOW,\n",
        "    maxlen = max_sequence_length,\n",
        "    dtype = 'float32',\n",
        "    padding = 'post',\n",
        "    truncating = 'post'\n",
        ")\n",
        "\n",
        "# print(embeddings_CBOW)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3fb574db",
      "metadata": {
        "id": "3fb574db"
      },
      "outputs": [],
      "source": [
        "# Padding sequences to the same length -> adding zeroes to the sequences shorter than embedding_dim and cutting sequences longer than embedding_dim\n",
        "# Converting to NumPy array\n",
        "embeddings_SG = pad_sequences(\n",
        "    list_of_embeddings_SG,\n",
        "    maxlen = max_sequence_length,\n",
        "    dtype = 'float32',\n",
        "    padding = 'post',\n",
        "    truncating = 'post'\n",
        ")\n",
        "\n",
        "# print(embeddings_SG)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "622b2489",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "622b2489",
        "outputId": "d3a98956-4b97-4979-b482-3d4b8686ef51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimensions of embeddings_CBOW: (7505, 30, 300)\n",
            "Dimensions of embeddings_SG: (7505, 30, 300)\n",
            "Dimensions of target value: (7505, 7)\n"
          ]
        }
      ],
      "source": [
        "# One-hot encoding of target values\n",
        "y = to_categorical(ISEAR_data['emotion_label'], num_classes=num_classes)\n",
        "y_original_labels = ISEAR_data['emotion_label'].values\n",
        "\n",
        "print(f\"Dimensions of embeddings_CBOW: {embeddings_CBOW.shape}\") # (number_of_examples, sequence_length, embedding_dim)\n",
        "print(f\"Dimensions of embeddings_SG: {embeddings_SG.shape}\") # (number_of_examples, sequence_length, embedding_dim)\n",
        "print(f\"Dimensions of target value: {y.shape}\") # (number_of_examples, num_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ce781f5",
      "metadata": {
        "id": "5ce781f5"
      },
      "source": [
        "# RNN predictions for Word2Vec embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71d09564",
      "metadata": {
        "id": "71d09564"
      },
      "source": [
        "### Predictions for SG embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f94496e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3f94496e",
        "outputId": "aca6db33-624c-4b1b-8474-c2bb3467eb77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Training Fold 1/5 ---\n",
            "Epoch 14: early stopping\n",
            "Restoring model weights from the end of the best epoch: 9.\n",
            "   Fold 1 - Val Loss: 1.3983, Val Acc: 0.5396, Val Precision-macro: 0.5411, Val Recall-macro: 0.5398, Val F1-macro: 0.5381, Val AUC-macro: 0.8521\n",
            "   Confusion Matrix:\n",
            "[[ 85  38   5  27  10  29  20]\n",
            " [ 16 118   9  15  13  19  22]\n",
            " [ 13  18 128  12   6  25  14]\n",
            " [ 18  20   9  97  15  19  36]\n",
            " [  7   8   6   4 159  21   8]\n",
            " [ 17  11  11  17  22 128  10]\n",
            " [ 26  21  10  40  13  11  95]]\n",
            "\n",
            "--- Training Fold 2/5 ---\n",
            "Epoch 12: early stopping\n",
            "Restoring model weights from the end of the best epoch: 7.\n",
            "   Fold 2 - Val Loss: 1.3057, Val Acc: 0.5430, Val Precision-macro: 0.5520, Val Recall-macro: 0.5431, Val F1-macro: 0.5396, Val AUC-macro: 0.8515\n",
            "   Confusion Matrix:\n",
            "[[126  16   6  22  11  19  14]\n",
            " [ 50 105  19   6  12   9  11]\n",
            " [ 23  12 137  12  10  17   5]\n",
            " [ 55   9  16  90   7  15  22]\n",
            " [ 14   8   7   9 156  19   0]\n",
            " [ 20   6  11  17  23 131   8]\n",
            " [ 35  20  20  39  23   9  70]]\n",
            "\n",
            "--- Training Fold 3/5 ---\n",
            "Epoch 11: early stopping\n",
            "Restoring model weights from the end of the best epoch: 6.\n",
            "   Fold 3 - Val Loss: 1.2960, Val Acc: 0.5396, Val Precision-macro: 0.5502, Val Recall-macro: 0.5398, Val F1-macro: 0.5398, Val AUC-macro: 0.8509\n",
            "   Confusion Matrix:\n",
            "[[108  13  16  23  26   3  25]\n",
            " [ 40 110  13   6  12   5  25]\n",
            " [ 15  11 150   9  12  11   8]\n",
            " [ 43   5  11  90  16  15  34]\n",
            " [ 14   3   8   3 152  15  18]\n",
            " [ 28   7  11   9  35 111  15]\n",
            " [ 27  16  19  42  15   9  89]]\n",
            "\n",
            "--- Training Fold 4/5 ---\n",
            "Epoch 10: early stopping\n",
            "Restoring model weights from the end of the best epoch: 5.\n",
            "   Fold 4 - Val Loss: 1.2752, Val Acc: 0.5523, Val Precision-macro: 0.5678, Val Recall-macro: 0.5528, Val F1-macro: 0.5493, Val AUC-macro: 0.8555\n",
            "   Confusion Matrix:\n",
            "[[113  23  17  34   6  13   8]\n",
            " [ 28 126  16  16   6  10   9]\n",
            " [ 15  11 155  11   4  13   7]\n",
            " [ 50  10  15 106   5  13  15]\n",
            " [ 13  11  12  15 142  16   4]\n",
            " [ 16   4  22  26   8 135   5]\n",
            " [ 43  22  17  67   7   9  52]]\n",
            "\n",
            "--- Training Fold 5/5 ---\n",
            "Epoch 13: early stopping\n",
            "Restoring model weights from the end of the best epoch: 8.\n",
            "   Fold 5 - Val Loss: 1.3433, Val Acc: 0.5503, Val Precision-macro: 0.5581, Val Recall-macro: 0.5507, Val F1-macro: 0.5473, Val AUC-macro: 0.8571\n",
            "   Confusion Matrix:\n",
            "[[ 82  28   9  46  15  27   7]\n",
            " [ 25 120   8  18  13  19   9]\n",
            " [  8  21 138  16  13  16   3]\n",
            " [ 20   9  10 117  11  28  19]\n",
            " [  2   9   2  12 160  21   7]\n",
            " [ 14  12   7  22  21 127  13]\n",
            " [ 15  22  15  48  20  15  82]]\n"
          ]
        }
      ],
      "source": [
        "# Model parameters\n",
        "n_splits = 5 # 5-fold cross-validation\n",
        "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "epochs = 50\n",
        "batch_size = 32\n",
        "lstm_units = 128\n",
        "dropout_rate = 0.3\n",
        "\n",
        "fold_accuracies = []\n",
        "fold_losses = []\n",
        "fold_f1_macros = []\n",
        "fold_auc_macros = []\n",
        "fold_precision_macros = []\n",
        "fold_recall_macros = []\n",
        "fold_confusion_matrices = []\n",
        "\n",
        "for fold, (train_index, val_index) in enumerate(skf.split(embeddings_SG, y_original_labels)):\n",
        "    print(f\"\\n--- Training Fold {fold + 1}/{n_splits} ---\")\n",
        "\n",
        "    X_train_fold, X_val_fold = embeddings_SG[train_index], embeddings_SG[val_index]\n",
        "    y_train_fold, y_val_fold = y[train_index], y[val_index]\n",
        "\n",
        "    clear_session()  # Reseting Keras session to build new model\n",
        "\n",
        "    # Build LSTM Bidirectional model\n",
        "    model = Sequential()\n",
        "    model.add(Input(shape=(max_sequence_length, embedding_dim_SG)))\n",
        "    model.add(Bidirectional(LSTM(lstm_units, return_sequences=False)))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    early_stopping_callback = EarlyStopping(\n",
        "        monitor='val_accuracy',\n",
        "        patience=5,\n",
        "        restore_best_weights=True,\n",
        "        mode='max',\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Training\n",
        "    history = model.fit(\n",
        "        X_train_fold, y_train_fold,\n",
        "        epochs=epochs,\n",
        "        batch_size=batch_size,\n",
        "        validation_data=(X_val_fold, y_val_fold),\n",
        "        callbacks=[early_stopping_callback],\n",
        "        verbose=0\n",
        "    )\n",
        "\n",
        "    # Evaluation\n",
        "    loss, accuracy = model.evaluate(X_val_fold, y_val_fold, verbose=0)\n",
        "    fold_losses.append(loss)\n",
        "    fold_accuracies.append(accuracy)\n",
        "\n",
        "    y_pred_probs_fold = model.predict(X_val_fold, verbose=0)\n",
        "    y_pred_classes_fold = np.argmax(y_pred_probs_fold, axis=1)\n",
        "    y_true_classes_fold = np.argmax(y_val_fold, axis=1)\n",
        "\n",
        "    precision_macro_fold = precision_score(y_true_classes_fold, y_pred_classes_fold, average='macro', zero_division=0)\n",
        "    recall_macro_fold = recall_score(y_true_classes_fold, y_pred_classes_fold, average='macro', zero_division=0)\n",
        "    f1_macro_fold = f1_score(y_true_classes_fold, y_pred_classes_fold, average='macro', zero_division=0)\n",
        "\n",
        "    fold_precision_macros.append(precision_macro_fold)\n",
        "    fold_recall_macros.append(recall_macro_fold)\n",
        "    fold_f1_macros.append(f1_macro_fold)\n",
        "\n",
        "    try:\n",
        "        auc_macro_fold = roc_auc_score(y_true_classes_fold, y_pred_probs_fold, multi_class='ovr', average='macro')\n",
        "        fold_auc_macros.append(auc_macro_fold)\n",
        "    except ValueError:\n",
        "        fold_auc_macros.append(np.nan)\n",
        "\n",
        "    # --- Confusion matrix ---\n",
        "    cm = confusion_matrix(y_true_classes_fold, y_pred_classes_fold)\n",
        "    fold_confusion_matrices.append(cm)\n",
        "\n",
        "    print(f\"   Fold {fold + 1} - Val Loss: {loss:.4f}, Val Acc: {accuracy:.4f}, \"\n",
        "          f\"Val Precision-macro: {precision_macro_fold:.4f}, Val Recall-macro: {recall_macro_fold:.4f}, \"\n",
        "          f\"Val F1-macro: {f1_macro_fold:.4f}, Val AUC-macro: {fold_auc_macros[-1]:.4f}\")\n",
        "    print(f\"   Confusion Matrix:\\n{cm}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e0d85ef",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0e0d85ef",
        "outputId": "42afd0de-a232-4355-bbf4-7c8ffb4a6fa4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Average cross validation results for Word2Vec SG embeddings ---\n",
            "Loss: 1.3237 +/- 0.0433\n",
            "Accuracy: 0.5450 +/- 0.0053\n",
            "Precision-macro: 0.5538 +/- 0.0089\n",
            "Recall-macro: 0.5452 +/- 0.0055\n",
            "F1-macro: 0.5428 +/- 0.0045\n",
            "AUC-macro: 0.8534 +/- 0.0024\n",
            "Average Confusion Matrix across folds:\n",
            "[[102  23  10  30  13  18  14]\n",
            " [ 31 115  13  12  11  12  15]\n",
            " [ 14  14 141  12   9  16   7]\n",
            " [ 37  10  12 100  10  18  25]\n",
            " [ 10   7   7   8 153  18   7]\n",
            " [ 19   8  12  18  21 126  10]\n",
            " [ 29  20  16  47  15  10  77]]\n"
          ]
        }
      ],
      "source": [
        "# Calculation of average results across all folds +/ std.dev\n",
        "print(\"\\n--- Average cross validation results for Word2Vec SG embeddings ---\")\n",
        "print(f\"Loss: {np.mean(fold_losses):.4f} +/- {np.std(fold_losses):.4f}\")\n",
        "print(f\"Accuracy: {np.mean(fold_accuracies):.4f} +/- {np.std(fold_accuracies):.4f}\")\n",
        "print(f\"Precision-macro: {np.mean(fold_precision_macros):.4f} +/- {np.std(fold_precision_macros):.4f}\")\n",
        "print(f\"Recall-macro: {np.mean(fold_recall_macros):.4f} +/- {np.std(fold_recall_macros):.4f}\")\n",
        "print(f\"F1-macro: {np.mean(fold_f1_macros):.4f} +/- {np.std(fold_f1_macros):.4f}\")\n",
        "print(f\"AUC-macro: {np.nanmean(fold_auc_macros):.4f} +/- {np.nanstd(fold_auc_macros):.4f}\")\n",
        "avg_confusion_matrix = np.mean(fold_confusion_matrices, axis=0)\n",
        "print(f\"Average Confusion Matrix across folds:\\n{avg_confusion_matrix.astype(int)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e020a5a9",
      "metadata": {
        "id": "e020a5a9"
      },
      "source": [
        "### Predictions for CBOW embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3160b1d1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3160b1d1",
        "outputId": "f2d28987-300f-4987-ee47-adc70667ee2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Training Fold 1/5 ---\n",
            "Epoch 27: early stopping\n",
            "Restoring model weights from the end of the best epoch: 22.\n",
            "   Fold 1 - Val Loss: 1.4503, Val Acc: 0.5157, Val Precision-macro: 0.5192, Val Recall-macro: 0.5158, Val F1-macro: 0.5020, Val AUC-macro: 0.8364\n",
            "   Confusion Matrix:\n",
            "[[ 97  22  14  15  27  30   9]\n",
            " [ 31  97  29   7  21  20   7]\n",
            " [  9   7 143   8  17  27   5]\n",
            " [ 32  14  26  85  19  28  10]\n",
            " [  7   2  12   6 167  17   2]\n",
            " [ 20  14  14   5  25 133   5]\n",
            " [ 38  25  21  45  18  17  52]]\n",
            "\n",
            "--- Training Fold 2/5 ---\n",
            "Epoch 25: early stopping\n",
            "Restoring model weights from the end of the best epoch: 20.\n",
            "   Fold 2 - Val Loss: 1.3549, Val Acc: 0.5150, Val Precision-macro: 0.5361, Val Recall-macro: 0.5148, Val F1-macro: 0.5138, Val AUC-macro: 0.8392\n",
            "   Confusion Matrix:\n",
            "[[119  14  12  29   6  20  14]\n",
            " [ 60  78  24  13   7  10  20]\n",
            " [ 20   8 144  18   6  17   3]\n",
            " [ 46   3  13 107   8  14  23]\n",
            " [ 18   9   7  15 129  28   7]\n",
            " [ 21   4  11  27  14 130   9]\n",
            " [ 37   6  22  58  16  11  66]]\n",
            "\n",
            "--- Training Fold 3/5 ---\n",
            "Epoch 24: early stopping\n",
            "Restoring model weights from the end of the best epoch: 19.\n",
            "   Fold 3 - Val Loss: 1.3819, Val Acc: 0.4910, Val Precision-macro: 0.4956, Val Recall-macro: 0.4910, Val F1-macro: 0.4894, Val AUC-macro: 0.8299\n",
            "   Confusion Matrix:\n",
            "[[ 82  17  17  34  20  13  31]\n",
            " [ 32  99  27   9   9  10  25]\n",
            " [ 13   7 150   9  11  10  16]\n",
            " [ 33   6  12  72  10  23  58]\n",
            " [ 18   5  14   3 143  15  15]\n",
            " [ 19  11  18  18  28 102  20]\n",
            " [ 27  15  23  38  19   6  89]]\n",
            "\n",
            "--- Training Fold 4/5 ---\n",
            "Epoch 24: early stopping\n",
            "Restoring model weights from the end of the best epoch: 19.\n",
            "   Fold 4 - Val Loss: 1.3802, Val Acc: 0.5137, Val Precision-macro: 0.5185, Val Recall-macro: 0.5142, Val F1-macro: 0.5055, Val AUC-macro: 0.8345\n",
            "   Confusion Matrix:\n",
            "[[114  23   6  29  16  15  11]\n",
            " [ 29 106  16  14  21  16   9]\n",
            " [ 20   4 130  16  20  16  10]\n",
            " [ 42   8  19  94  14  20  17]\n",
            " [ 11   5   9  12 158  18   0]\n",
            " [ 27   6  16  15  29 121   2]\n",
            " [ 39  26  18  61  12  13  48]]\n",
            "\n",
            "--- Training Fold 5/5 ---\n",
            "Epoch 30: early stopping\n",
            "Restoring model weights from the end of the best epoch: 25.\n",
            "   Fold 5 - Val Loss: 1.5074, Val Acc: 0.5010, Val Precision-macro: 0.5078, Val Recall-macro: 0.5012, Val F1-macro: 0.4980, Val AUC-macro: 0.8255\n",
            "   Confusion Matrix:\n",
            "[[112  22  13  19  24  15   9]\n",
            " [ 46  89  14  11  27  11  14]\n",
            " [ 13  13 124  12  21  23   9]\n",
            " [ 52   9  10  74  15  23  31]\n",
            " [ 11   8   4   7 156  14  13]\n",
            " [ 26  11  10  20  24 110  15]\n",
            " [ 37  11  13  30  21  18  87]]\n"
          ]
        }
      ],
      "source": [
        "# Model parameters\n",
        "n_splits = 5 # 5-fold cross-validation\n",
        "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "epochs = 50\n",
        "batch_size = 32\n",
        "lstm_units = 128\n",
        "dropout_rate = 0.3\n",
        "\n",
        "fold_accuracies = []\n",
        "fold_losses = []\n",
        "fold_f1_macros = []\n",
        "fold_auc_macros = []\n",
        "fold_precision_macros = []\n",
        "fold_recall_macros = []\n",
        "fold_confusion_matrices = []\n",
        "\n",
        "for fold, (train_index, val_index) in enumerate(skf.split(embeddings_CBOW, y_original_labels)):\n",
        "    print(f\"\\n--- Training Fold {fold + 1}/{n_splits} ---\")\n",
        "\n",
        "    X_train_fold, X_val_fold = embeddings_CBOW[train_index], embeddings_CBOW[val_index]\n",
        "    y_train_fold, y_val_fold = y[train_index], y[val_index]\n",
        "\n",
        "    clear_session() # Reseting Keras session to build new model\n",
        "\n",
        "    # Building an LSTM Bidirectional model\n",
        "    model = Sequential()\n",
        "    model.add(Input(shape=(max_sequence_length, embedding_dim_CBOW)))\n",
        "    model.add(Bidirectional(LSTM(lstm_units, return_sequences=False)))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    # EarlyStopping Callback - to prevent model of overfitting\n",
        "    early_stopping_callback = EarlyStopping(\n",
        "        monitor='val_accuracy', # We are tracking validation accuracy\n",
        "        patience=5,             # The training stops if the val_accuracy doesn't get better after 5 epochs\n",
        "        restore_best_weights=True,\n",
        "        mode='max',             # Maximizing accuracy\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Training the model\n",
        "    history = model.fit(\n",
        "        X_train_fold, y_train_fold,\n",
        "        epochs=50,   # trining in 50 epochs (we assume early stopping call back will end the training before)\n",
        "        batch_size=batch_size,\n",
        "        validation_data=(X_val_fold, y_val_fold),\n",
        "        callbacks=[early_stopping_callback],\n",
        "        verbose=0\n",
        "    )\n",
        "\n",
        "    # Evaluating the model\n",
        "    loss, accuracy = model.evaluate(X_val_fold, y_val_fold, verbose=0)\n",
        "    fold_losses.append(loss)\n",
        "    fold_accuracies.append(accuracy)\n",
        "\n",
        "    y_pred_probs_fold = model.predict(X_val_fold, verbose=0)\n",
        "    y_pred_classes_fold = np.argmax(y_pred_probs_fold, axis=1)\n",
        "    y_true_classes_fold = np.argmax(y_val_fold, axis=1)\n",
        "\n",
        "    precision_macro_fold = precision_score(y_true_classes_fold, y_pred_classes_fold, average='macro', zero_division=0)\n",
        "    recall_macro_fold = recall_score(y_true_classes_fold, y_pred_classes_fold, average='macro', zero_division=0)\n",
        "\n",
        "    fold_precision_macros.append(precision_macro_fold)\n",
        "    fold_recall_macros.append(recall_macro_fold)\n",
        "\n",
        "    f1_macro_fold = f1_score(y_true_classes_fold, y_pred_classes_fold, average='macro', zero_division=0)\n",
        "    fold_f1_macros.append(f1_macro_fold)\n",
        "\n",
        "    try:\n",
        "        auc_macro_fold = roc_auc_score(y_true_classes_fold, y_pred_probs_fold, multi_class='ovr', average='macro')\n",
        "        fold_auc_macros.append(auc_macro_fold)\n",
        "    except ValueError as e:\n",
        "        fold_auc_macros.append(np.nan)\n",
        "\n",
        "    # --- Confusion matrix ---\n",
        "    cm = confusion_matrix(y_true_classes_fold, y_pred_classes_fold)\n",
        "    fold_confusion_matrices.append(cm)\n",
        "\n",
        "    print(f\"   Fold {fold + 1} - Val Loss: {loss:.4f}, Val Acc: {accuracy:.4f}, \"\n",
        "          f\"Val Precision-macro: {precision_macro_fold:.4f}, Val Recall-macro: {recall_macro_fold:.4f}, \"\n",
        "          f\"Val F1-macro: {f1_macro_fold:.4f}, Val AUC-macro: {fold_auc_macros[-1]:.4f}\")\n",
        "    print(f\"   Confusion Matrix:\\n{cm}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b6f0222",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1b6f0222",
        "outputId": "52a1ba70-93dd-4118-896c-cc784b93f9ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Average cross validation results for Word2Vec CBOW embeddings ---\n",
            "Val Loss: 1.4150 +/- 0.0561\n",
            "Val Accuracy: 0.5073 +/- 0.0097\n",
            "Val Precision-macro: 0.5154 +/- 0.0134\n",
            "Val Recall-macro: 0.5074 +/- 0.0098\n",
            "Val F1-macro: 0.5017 +/- 0.0081\n",
            "Val AUC-macro: 0.8331 +/- 0.0048\n",
            "Average Confusion Matrix across folds:\n",
            "[[104  19  12  25  18  18  14]\n",
            " [ 39  93  22  10  17  13  15]\n",
            " [ 15   7 138  12  15  18   8]\n",
            " [ 41   8  16  86  13  21  27]\n",
            " [ 13   5   9   8 150  18   7]\n",
            " [ 22   9  13  17  24 119  10]\n",
            " [ 35  16  19  46  17  13  68]]\n"
          ]
        }
      ],
      "source": [
        "# Calculation of average results across all folds +/ std.dev\n",
        "print(\"\\n--- Average cross validation results for Word2Vec CBOW embeddings ---\")\n",
        "print(f\"Val Loss: {np.mean(fold_losses):.4f} +/- {np.std(fold_losses):.4f}\")\n",
        "print(f\"Val Accuracy: {np.mean(fold_accuracies):.4f} +/- {np.std(fold_accuracies):.4f}\")\n",
        "print(f\"Val Precision-macro: {np.mean(fold_precision_macros):.4f} +/- {np.std(fold_precision_macros):.4f}\")\n",
        "print(f\"Val Recall-macro: {np.mean(fold_recall_macros):.4f} +/- {np.std(fold_recall_macros):.4f}\")\n",
        "print(f\"Val F1-macro: {np.mean(fold_f1_macros):.4f} +/- {np.std(fold_f1_macros):.4f}\")\n",
        "print(f\"Val AUC-macro: {np.nanmean(fold_auc_macros):.4f} +/- {np.nanstd(fold_auc_macros):.4f}\")\n",
        "avg_confusion_matrix = np.mean(fold_confusion_matrices, axis=0)\n",
        "print(f\"Average Confusion Matrix across folds:\\n{avg_confusion_matrix.astype(int)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d49afe98",
      "metadata": {
        "id": "d49afe98"
      },
      "source": [
        "# BERT Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5e6a454",
      "metadata": {
        "id": "c5e6a454"
      },
      "outputs": [],
      "source": [
        "# Import of fine tuned bert model\n",
        "#model_path = \"/content/drive/My Drive/modeli/BERT_5\"\n",
        "model_path = \"/content/drive/My Drive/fine_tuned_bert\"\n",
        "bert_model = BertForMaskedLM.from_pretrained(model_path)\n",
        "bert_tokenizer = BertTokenizer.from_pretrained(model_path)\n",
        "embedding_dim_bert = bert_model.config.hidden_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc265cb3",
      "metadata": {
        "id": "bc265cb3"
      },
      "outputs": [],
      "source": [
        "# Function for getting bert embeddings\n",
        "def get_bert_embeddings(sentence, bert_model, bert_tokenizer, max_sequence_length_for_lstm):\n",
        "\n",
        "    padding_zeroes = np.zeros(embedding_dim_bert, dtype=np.float32) # used to pad sequences shorter than sequence_length (50)\n",
        "\n",
        "    inputs = bert_tokenizer(\n",
        "        sentence,\n",
        "        return_tensors='pt',\n",
        "        truncation=True\n",
        "    )\n",
        "\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    bert_model.to(device)\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = bert_model(\n",
        "            input_ids=inputs['input_ids'],\n",
        "            attention_mask=inputs.get('attention_mask', None),\n",
        "            token_type_ids=inputs.get('token_type_ids', None),\n",
        "            output_hidden_states=True\n",
        "        )\n",
        "\n",
        "    # Last hidden state: (seq_len, embedding_dim)\n",
        "    token_embeddings = outputs.hidden_states[-1].squeeze(0).cpu().numpy()\n",
        "    input_ids = inputs['input_ids'].squeeze(0).cpu().numpy()\n",
        "\n",
        "    # Filter out special tokens\n",
        "    filtered_embeddings = []\n",
        "    for i, token_id in enumerate(input_ids):\n",
        "        token_str = bert_tokenizer.decode([token_id])\n",
        "        if token_str in bert_tokenizer.all_special_tokens or not token_str.strip():\n",
        "            continue\n",
        "        filtered_embeddings.append(token_embeddings[i])\n",
        "\n",
        "    return np.array(filtered_embeddings, dtype=np.float32)  # shape: (seq_len, embedding_dim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b0f8a00",
      "metadata": {
        "id": "4b0f8a00"
      },
      "outputs": [],
      "source": [
        "# Getting bert embeddings for each word in the sentence\n",
        "list_of_embeddings_BERT = [\n",
        "   get_bert_embeddings(text, bert_model, bert_tokenizer, max_sequence_length)\n",
        "    for text in ISEAR_data['text']\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a6e350c",
      "metadata": {
        "id": "8a6e350c"
      },
      "outputs": [],
      "source": [
        "# Padding sequences to the same length -> adding zeroes to the sequences shorter than embedding_dim and cutting sequences longer than embedding_dim\n",
        "# Converting to NumPy array\n",
        "embeddings_BERT = pad_sequences(\n",
        "    list_of_embeddings_BERT,\n",
        "    maxlen = max_sequence_length,\n",
        "    dtype = 'float32',\n",
        "    padding = 'post',\n",
        "    truncating = 'post'\n",
        ")\n",
        "\n",
        "# print (embeddings_BERT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de4ea499",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "de4ea499",
        "outputId": "f502f8db-12a0-424e-eb73-37a73f5f4444"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dimensions of embeddings_BERT: (7505, 30, 768)\n",
            "Dimensions of target value: (7505, 7)\n"
          ]
        }
      ],
      "source": [
        "# One-hot encoding of target values\n",
        "y = to_categorical(ISEAR_data['emotion_label'], num_classes=num_classes)\n",
        "\n",
        "print(f\"\\nDimensions of embeddings_BERT: {embeddings_BERT.shape}\") # (number_of_examples, sequence_length, embedding_dim)\n",
        "print(f\"Dimensions of target value: {y.shape}\") # (number_of_examples, num_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1dc2d0dc",
      "metadata": {
        "id": "1dc2d0dc"
      },
      "source": [
        "# RNN predictions for BERT Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5f360f6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5f360f6",
        "outputId": "ca820ace-eef4-4728-f80f-f58edebfb160"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Training Fold 1/5 ---\n",
            "Epoch 20: early stopping\n",
            "Restoring model weights from the end of the best epoch: 15.\n",
            "   Fold 1 - Val Loss: 1.8591, Val Acc: 0.6342\n",
            "\n",
            "--- Training Fold 2/5 ---\n",
            "Epoch 15: early stopping\n",
            "Restoring model weights from the end of the best epoch: 10.\n",
            "   Fold 2 - Val Loss: 1.4480, Val Acc: 0.6149\n",
            "\n",
            "--- Training Fold 3/5 ---\n",
            "Epoch 11: early stopping\n",
            "Restoring model weights from the end of the best epoch: 6.\n",
            "   Fold 3 - Val Loss: 1.0871, Val Acc: 0.6422\n",
            "\n",
            "--- Training Fold 4/5 ---\n",
            "Epoch 12: early stopping\n",
            "Restoring model weights from the end of the best epoch: 7.\n",
            "   Fold 4 - Val Loss: 1.0908, Val Acc: 0.6382\n",
            "\n",
            "--- Training Fold 5/5 ---\n",
            "Epoch 12: early stopping\n",
            "Restoring model weights from the end of the best epoch: 7.\n",
            "   Fold 5 - Val Loss: 1.1295, Val Acc: 0.6342\n"
          ]
        }
      ],
      "source": [
        "# Model parameters\n",
        "n_splits = 5 # 5-fold cross-validation\n",
        "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "epochs = 50\n",
        "batch_size = 32\n",
        "lstm_units = 128\n",
        "dropout_rate = 0.3\n",
        "\n",
        "fold_accuracies = []\n",
        "fold_losses = []\n",
        "fold_f1_macros = []\n",
        "fold_auc_macros = []\n",
        "fold_precision_macros = []\n",
        "fold_recall_macros = []\n",
        "fold_confusion_matrices = []\n",
        "\n",
        "for fold, (train_index, val_index) in enumerate(skf.split(embeddings_BERT, y_original_labels)):\n",
        "    print(f\"\\n--- Training Fold {fold + 1}/{n_splits} ---\")\n",
        "\n",
        "    X_train_fold, X_val_fold = embeddings_BERT[train_index], embeddings_BERT[val_index]\n",
        "    y_train_fold, y_val_fold = y[train_index], y[val_index]\n",
        "\n",
        "    clear_session() # Reseting Keras session to build new model\n",
        "\n",
        "    # Building an LSTM Bidirectional model\n",
        "    model = Sequential()\n",
        "    model.add(Input(shape=(max_sequence_length, embedding_dim_bert)))\n",
        "    model.add(Bidirectional(LSTM(lstm_units, return_sequences=False)))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    # EarlyStopping Callback - to prevent model of overfitting\n",
        "    early_stopping_callback = EarlyStopping(\n",
        "        monitor='val_accuracy', # We are tracking validation accuracy\n",
        "        patience=5,             # The training stops if the val_accuracy doesn't get better after 5 epochs\n",
        "        restore_best_weights=True,\n",
        "        mode='max',             # Maximizing accuracy\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Training the model\n",
        "    history = model.fit(\n",
        "        X_train_fold, y_train_fold,\n",
        "        epochs=50,   # trining in 50 epochs (we assume early stopping call back will end the training before)\n",
        "        batch_size=batch_size,\n",
        "        validation_data=(X_val_fold, y_val_fold),\n",
        "        callbacks=[early_stopping_callback],\n",
        "        verbose=0\n",
        "    )\n",
        "\n",
        "    # Evaluating the model\n",
        "    loss, accuracy = model.evaluate(X_val_fold, y_val_fold, verbose=0)\n",
        "    fold_losses.append(loss)\n",
        "    fold_accuracies.append(accuracy)\n",
        "\n",
        "    y_pred_probs_fold = model.predict(X_val_fold, verbose=0)\n",
        "    y_pred_classes_fold = np.argmax(y_pred_probs_fold, axis=1)\n",
        "    y_true_classes_fold = np.argmax(y_val_fold, axis=1)\n",
        "\n",
        "    precision_macro_fold = precision_score(y_true_classes_fold, y_pred_classes_fold, average='macro', zero_division=0)\n",
        "    recall_macro_fold = recall_score(y_true_classes_fold, y_pred_classes_fold, average='macro', zero_division=0)\n",
        "\n",
        "    fold_precision_macros.append(precision_macro_fold)\n",
        "    fold_recall_macros.append(recall_macro_fold)\n",
        "\n",
        "    f1_macro_fold = f1_score(y_true_classes_fold, y_pred_classes_fold, average='macro', zero_division=0)\n",
        "    fold_f1_macros.append(f1_macro_fold)\n",
        "\n",
        "    try:\n",
        "        auc_macro_fold = roc_auc_score(y_true_classes_fold, y_pred_probs_fold, multi_class='ovr', average='macro')\n",
        "        fold_auc_macros.append(auc_macro_fold)\n",
        "    except ValueError as e:\n",
        "        fold_auc_macros.append(np.nan)\n",
        "\n",
        "   # --- Confusion matrix ---\n",
        "    cm = confusion_matrix(y_true_classes_fold, y_pred_classes_fold)\n",
        "    fold_confusion_matrices.append(cm)\n",
        "\n",
        "    print(f\"   Fold {fold + 1} - Val Loss: {loss:.4f}, Val Acc: {accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33ebdc48",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33ebdc48",
        "outputId": "46578683-55e4-48e8-a5d8-cc0acac367eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Average cross validation results for BERT embeddings ---\n",
            "Val Loss: 1.3229 +/- 0.3000\n",
            "Val Accuracy: 0.6328 +/- 0.0094\n",
            "Val Precision-macro: 0.6426 +/- 0.0148\n",
            "Val Recall-macro: 0.6329 +/- 0.0094\n",
            "Val F1-macro: 0.6321 +/- 0.0088\n",
            "Val AUC-macro: 0.8984 +/- 0.0052\n",
            "Average Confusion Matrix across folds:\n",
            "[[118  26  10  19   6  11  21]\n",
            " [ 32 129  11   9   4   7  17]\n",
            " [ 11   9 156   8   5  11  14]\n",
            " [ 25   8  11 108   3  14  43]\n",
            " [  4   2   4   3 180   9   8]\n",
            " [ 16  11  12  10  11 140  13]\n",
            " [ 21  14  12  38   7   6 116]]\n"
          ]
        }
      ],
      "source": [
        "# Calculation of average results across all folds +/ std.dev\n",
        "print(\"\\n--- Average cross validation results for BERT embeddings ---\")\n",
        "print(f\"Val Loss: {np.mean(fold_losses):.4f} +/- {np.std(fold_losses):.4f}\")\n",
        "print(f\"Val Accuracy: {np.mean(fold_accuracies):.4f} +/- {np.std(fold_accuracies):.4f}\")\n",
        "print(f\"Val Precision-macro: {np.mean(fold_precision_macros):.4f} +/- {np.std(fold_precision_macros):.4f}\")\n",
        "print(f\"Val Recall-macro: {np.mean(fold_recall_macros):.4f} +/- {np.std(fold_recall_macros):.4f}\")\n",
        "print(f\"Val F1-macro: {np.mean(fold_f1_macros):.4f} +/- {np.std(fold_f1_macros):.4f}\")\n",
        "print(f\"Val AUC-macro: {np.nanmean(fold_auc_macros):.4f} +/- {np.nanstd(fold_auc_macros):.4f}\")\n",
        "avg_confusion_matrix = np.mean(fold_confusion_matrices, axis=0)\n",
        "print(f\"Average Confusion Matrix across folds:\\n{avg_confusion_matrix.astype(int)}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}